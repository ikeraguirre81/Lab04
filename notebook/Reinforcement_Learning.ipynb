{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Aprendizajo por Refuerzo - Una aproximación teórica"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Autores**: Iker Aguirre y Carlos Serrano"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Fecha:** 15/01/2021"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tabla de Contenidos\n",
    "\n",
    "1. [Introducción](#intro)\n",
    "\n",
    "    1.1 [Elementos del aprendizaje por refuerzo](#elem)\n",
    "    \n",
    "    1.2 [Ejemplo : Tres en Raya](#raya)\n",
    "    \n",
    "\n",
    "2. [Métodos de Solución Tabular](#tabu)\n",
    "    \n",
    "    2.1 [Procesos finitos de Markov](#markov)\n",
    "    \n",
    "    2.2 [ Método de Monte Carlo](#monte)\n",
    "    \n",
    "\n",
    "3. [Métodos de Solución Aproximada](#aprox)\n",
    "    \n",
    "    3.1 [3.1 Predicción \"on-policy\" mediante aproximación](#onpolicy)\n",
    "\n",
    "\n",
    "4. [Caso de estudio: Las Damas de Samuel](#samuel)\n",
    "\n",
    "\n",
    "5. [Conclusiones](#conclu)\n",
    "\n",
    "\n",
    "[Bibliografía](#biblio)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Introducción\n",
    "\n",
    "<a id=\"intro\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La interacción con el entorno es una forma muy importante de aprendizaje en el ser humano. Este es un proceso constante, donde el sujeto se tiene que adaptar continuamente a los estímulos de su entorno para lograr su objetivo, su recompensa. Cada acción que realizamos en nuestra vida diaria, conlleva una experiencia, que condicionará las decisiones que tomemos en el futuro. El sujeto, es decir, nosotros, deberemos ser capaces de asimilar esa experiencia para tomar decisiones que nos acerquen a nuestra recompensa cada vez más óptimas. Cómo de rápidos o eficientes seamos al comprender nuestro entorno, y actuar en consecuencia es un determinante de nuestra inteligencia. \n",
    "Este concepto es recogido por el aprendizaje por refuerzo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El aprendizaje por refuerzo es aprender qué hacer, es decir, cómo conectar las situaciones a las acciones, para así, maximizar una señal de recompensa numérica. No se le dice al sujeto qué acciones debe llevar a cabo, este debe, en cambio, descubrir qué acciones producen la mayor recompensa al probarlas. En los casos más interesantes, las acciones pueden afectar no sólo a la inmediata, pero también la siguiente situación y, a través de ella, todas las recompensas posteriores. Estas dos características , es decir, prueba y error y recompensa retrasada, son las más importantes del aprendizaje por refuerzo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Diferencias con otros tipos de aprendizaje"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El aprendizaje por refuerzo es diferente del *aprendizaje supervisado*, que es el tipo de aprendizaje empleado sobre todo en las investigaciones que utilizan machine learning. El aprendizaje supervisado es el aprendizaje de un conjunto de respuestas conocidas proporcionados por un supervisor externo.\n",
    "\n",
    "Cada ejemplo es una descripción de una situación junto con una especificación (la etiqueta) de las respuestas correctas que el sistema debe adoptar ante esa situación, que a menudo consiste en identificar un categoría a la que pertenece la situación. El objeto de este tipo de aprendizaje generalizar las respuestas del sistema de manera que actúe correctamente en situaciones que no haya visto anteriormente. \n",
    "\n",
    "Este es un tipo de aprendizaje importante, pero por sí solo no es adecuado para aprender de la interacción. En los problemas interactivos a menudo no es práctico obtener ejemplos de comportamiento deseado que sean a la vez correctos y representativos de todos los situaciones en las que el agente tiene que actuar. \n",
    "\n",
    "En un territorio inexplorado, donde uno esperaría aprovechar el aprendizaje al máximo, un agente debe ser capaz de aprender de su propia experiencia.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El aprendizaje por refuerzo también es diferente de lo que es el *aprendizaje no supervisado*, que normalmente consiste en encontrar estructuras ocultas en colecciones de datos no etiquetados. Parecería que los términos aprendizaje supervisado y aprendizaje no supervisado sirviesen para clasificar exhaustivamente los paradigmas encontrados en Machine Learning, pero no lo hacen. \n",
    "\n",
    "Aunque uno podría estar tentado de pensar en el aprendizaje por refuerzo como una especie de aprendizaje no supervisado porque no se basa en ejemplos de comportamiento correcto, el aprendizaje por refuerzo está intentando para maximizar recompensa en lugar de tratar de encontrar una estructura oculta. \n",
    "\n",
    "Descubrir una estructura en la experiencia de un agente puede ser ciertamente útil en el aprendizaje por refuerzo, pero no aborda por sí solo el problema de aprendizaje de refuerzo de maximizar la recompensa.\n",
    "\n",
    "\n",
    "Por lo tanto, consideramos que el aprendizaje de refuerzo es un tercer paradigma del Machine Learning, junto con el aprendizaje supervisado y no supervisado y tal vez otros paradigmas.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 Elementos del aprendizaje por refuerzo\n",
    "\n",
    "<a id=\"elem\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Más allá del agente y el entorno, se pueden identificar cuatro subelementos principales de un sistema de aprendizaje por refuerzo: una política, una recompensa, una función valor y, opcionalmente, un modelo de entorno."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **Política**: define la manera de comportarse del agente en un momento dado. En términos generales, una política es una cartografía de los estados percibidos del medio ambiente a las medidas que deben adoptarse cuando se dan esos estados. Corresponde a lo que en psicología se llamaría un conjunto de reglas o asociaciones de estímulo-respuesta. En algunos casos, la política puede ser una simple función o tabla de búsqueda, mientras que en otros puede implicar un cálculo extenso como un proceso de búsqueda. La política es el núcleo de un agente de aprendizaje de refuerzo en el sentido de que por sí sola puede determinar el comportamiento. En general, las políticas pueden ser estocásticas, especificando probabilidades para cada acción."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **Recompensa**: Una señal de recompensa define el objetivo de un problema de aprendizaje por refuerzo. En cada paso, el entorno devuelve un número llamado recompensa. El objetivo del agente es maximizar la recompensa total que recibe en el largo plazo. La señal de recompensa define así cuáles son los eventos buenos y malos para el agente. En un sistema biológico, podríamos pensar que las recompensas son análogas a las experiencias de placer o de dolor. Son los factores definitorios del problema al que se enfrenta el agente. La recompensa condiciona la selección de políticas; si una acción seleccionada por la política es seguida de un premio pequeño, entonces la política puede ser cambiada para que cuando se le presente la misma situación en el futuro, esta elija otra opción diferente. Las recompensas pueden ser funciones estocásticas representando el estado del entorno y las acciones tomadas."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **Función-Valor**: define lo que es bueno a largo plazo. A grandes rasgos, el valor de un estado es la cantidad total de recompensa que un agente puede esperar acumular en el futuro, empezando desde ese estado. Mientras que las recompensas determinan la conveniencia inmediata e intrínseca de estados, los valores indican la conveniencia a largo plazo de los estados después de tomar en cuenta los estados que es probable que le sigan y las recompensas disponibles en esos estados. Por ejemplo, un estado siempre puede dar una baja recompensa inmediata pero aún así tener un alto valor porque es seguido por otros estados que producen altas recompensas. El contrario podría ser cierto también."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **Modelo**: Esto es algo que imita el comportamiento del entorno, o más generalmente, eso permite hacer inferencias sobre cómo se comportará el ambiente. No se puede dar en todos los sistemas de aprendizaje por refuerzo. Por ejemplo, dado un estado y una acción, el modelo podría predecir el próximo estado resultante y la próxima recompensa. Los modelos se utilizan para la planificación, con lo que nos referimos a cualquier forma de decidiren un curso de acción considerando posibles situaciones futuras antes de que sean realmente experimentado. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2. Ejemplo : Tres en Raya\n",
    "\n",
    "<a id=\"raya\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para ilustrar la idea general del aprendizaje de refuerzo y contrastarla con otros enfoques, a continuación consideramos un ejemplo con detalle, como es el juego de las tres en raya.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"tablero_3.PNG\" alt=\"Drawing\" style=\"width: 300px;\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dos jugadores se turnan para jugar en un tablero de tres por tres. Un jugador juega Xs y las otras Os hasta que un jugador gane colocando tres marcas en una fila, horizontal, vertical o diagonal, como el jugador X tiene en el juego que se muestra arriba. Si el tablero se llena, y ninguno de los jugadores consigue tres en una fila, entonces habrá empate.\n",
    "\n",
    "Debido a que un jugador hábil puede jugar para no perder nunca, asumamos que estamos jugando contra un jugador imperfecto, uno cuyo juego es a veces incorrecto y nos permite ganar. Por el momento, consideremos que los empates y las pérdidas son igualmente malos para nosotros. ¿Cómo podríamos construir un jugador que encuentre las imperfecciones en el juego de su oponente y aprenda a maximizar su posibilidades de ganar?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aunque se trata de un problema simple, no puede ser resuelto fácilmente de manera satisfactoriaa través de las técnicas clásicas. Por ejemplo, la clásica solución \"minimax\" no sería correcta aquí porque asume una forma particular de juego por parte del oponente. Por ejemplo, un jugador de minimax nunca alcanzaría un estado de juego desde el cual pudiera perder, incluso si de hecho siempre gana desde ese estado debido al juego incorrecto del oponente. Métodos clásicos de optimización para problemas de decisión secuenciales, como programación dinámica, pueden computar una solución óptima para cualquier oponente, pero requiere\n",
    "como entrada una especificación completa de ese oponente, incluyendo las probabilidades con las queel oponente hace cada movimiento en cada estado del tablero. Asumamos que esta informaciónno está disponible a priori para este problema, como no lo está para la gran mayoría de los problemas de interés práctico. Por otra parte, esa información puede estimarse a partir de la experiencia, en este caso jugando muchos juegos contra el oponente. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Un método evolutivo aplicado a este problema buscaría directamente en el espacio de las posibles políticas una con una alta probabilidad de ganar contra el oponente. Aquí, una política es una regla que le dice al jugador qué movimiento debe hacer para cada estado del juego (cada posible combinación de Xs y Os en el tablero). Para cada política considerada, se obtendría una estimación de su probabilidad de ganar jugando un cierto número de juegos contra el oponente. Esta evaluación entonces dirigiría qué políticas se considerarán a continuación. Un método evolutivo típico escalaría en el espacio de políticas, generando y evaluando sucesivamente políticas en un intento de obtener mejoras incrementales. O, quizás, se podría usar un algoritmo de estilo genético que mantendría y evaluaría una población de políticas. Literalmente cientos de métodos de optimización diferentes se podrían aplicar."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Por otro lado, podríamos enfrentarnos al problema con un método que utilize la Función-Valor. Primero estableceríamos una tabla de números, una para cada posible estado del juego. Cada número será la última estimación de la probabilidad de que ganemos\n",
    "desde ese estado. Tratamos esta estimación como el valor del estado, y toda la tabla es la función-valor aprendida. El estado A tiene un valor más alto que el estado B, o se considera \"mejor\" que el estado B, si la estimación real de la probabilidad de que ganemos de A es mayor que de B. Asumiendo que siempre jugamos con X, entonces para todos los estados con tres X seguidas\n",
    "la probabilidad de ganar es de 1. De manera similar, para todos los estados con tres O en una fila, la probabilidad correcta es 0. Fijamos los valores iniciales de todos los demás estados en 0.5, lo que representa un supuesto de tener un 50% posibilidades de ganar."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A continuación, jugamos muchas partidas contra el oponente. Para seleccionar nuestras jugadas examinamos estados que resultarían de cada uno de nuestros posibles movimientos (uno por cada espacio en blanco en el tablero) y buscamos sus valores reales en la tabla. La mayoría de las veces movemos con intención de ganar, seleccionando el movimiento que lleva al estado de mayor valor, es decir, con la mayor probabilidad estimada de ganar. Ocasionalmente, sin embargo, seleccionamos al azar entre los otros movimientos en su lugar. Estos se llaman movimientos exploratorios porque generan una experiencia que de otra manera nunca veríamos. En la siguiente figura, podemos ver una secuencia de juego."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"tres_en_raya_secuencia.PNG\" alt=\"Drawing\" style=\"width: 425px;\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mientras jugamos, cambiamos los valores de los estados en los que nos encontramos durante la partida. Intentamos hacer estimaciones más precisas de las probabilidades de ganar. Para ello, concociendo el valor del estado después de cada movimiento pensado para ganar, retrocedemos hacia el estado antes del movimiento, como sugieren las flechas de la de arriba. Más precisamente, el el valor actual del estado anterior se actualiza para estar más cerca del valor del estado posterior.\n",
    "\n",
    "\n",
    "Esto puede hacerse moviendo el valor del estado anterior una fracción del camino hacia el valor del estado posterior. Si dejamos que $S_{t}$ denote el estado antes del movimiento \"competitivo\", y $S_{t+1}$ el estado después del movimiento, la actualización al valor estimado de $S_{t}$, denotado $V (S_{t})$, puede escribirse como $$V (S_{t}) \\leftarrow V(S_{t}) + \\alpha[V (S_{t+1}) - V (S_{t})]$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Donde $\\alpha$ es una pequeña fracción positiva llamada *step-size parameter*, que influye en el ritmo de aprendizaje. Esta regla de actualización es un ejemplo de un aprendizaje *temporal-difference* llamado así porque sus cambios se basan en un diferencia, $V(S_{t+1}) - V(S_{t})$, entre estimaciones en dos momentos sucesivos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El método descrito anteriormente funciona bastante bien en esta tarea. Por ejemplo, si el $\\alpha$ se reduce adecuadamente con el tiempo, entonces este método converge, para cualquier oponente fijo, a las verdaderas probabilidades de ganar de cada estado dado nuestro jugador juegue de manera óptima. Además, los movimientos que se hacen entonces (excepto en los movimientos exploratorios) son de hecho, los movimientos óptimos contra este (imperfecto) oponente. En otras palabras, el método converge en una política óptima para jugar contra este oponente. Si el tamaño del paso no se reduce hasta cero con el tiempo, entonces este jugador también juega bien contra oponentes que cambian lentamente su forma de jugar."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Métodos de Solución Tabular\n",
    "\n",
    "<a id=\"tabu\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A continuación, vamos a repasar algunas ideas importantes y representar con ejercicios algunos de los algoritmos más sencillos del aprendizaje de refuerzo.Estos son aquellos en los que los espacios de estado y acción son lo suficientemente pequeños como para que las funciones-valor se representen como matrices o tablas. En en este caso, los métodos a menudo pueden encontrar soluciones exactas, es decir, a menudo pueden encontrar exactamente la función-valor óptima y la política óptima. Esto contrasta con los métodos de aproximación descritos en el siguiente apartado, que sólo encuentran soluciones aproximadas.\n",
    "\n",
    "En concreto vamos a hablar de dos de los métodos más conocidos como son los procesos finitos de Markov y el método de Monte Carlo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1.  Procesos finitos de Markov\n",
    "\n",
    "<a id=\"markov\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Los PDM (Procesos de Decisión de Markov) son una formalización clásica de la toma de decisiones secuenciales, donde las acciones influyen no sólo en las recompensas inmediatas, sino también en las situaciones posteriores, o estados, y a través de esas futuras recompensas. Así, los PDM implican una recompensa retrasada y la necesitan intercambiar recompensa inmediata y diferida."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para enterlo mejor, podemos utilizar con un ejemplo:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Ejemplo aplicado a Python"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Supongamos que Juan acaba de mudarse a Madrid y no conoce la ciudad. Quiere ir desde su casa hasta el trabajo en metro, pero no sabe el camino. Lo único que sabe es que tendrá que hacer varios transbordos para llegar a su destino final. \n",
    "\n",
    "Juan aprenderá a llegar al trabajo a base de intentar ir repetidas veces, siempre con un margen de tiempo para no llegar tarde. Por ello, ha representado un mapa de 8 puntos que recoge todas las rutas que podría seguir, siendo el punto 0 su casa, el 7 su lugar de trabajo, y el resto de puntos representando los distintos trasbordos que deberá hacer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pylab as plt\n",
    "\n",
    "puntos = [(0,1),(1,2),(2,3),(2,4),(1,5),(5,6),(5,7)]\n",
    "meta = 7"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Utilizamos el paquete \"networkx\" para representar el mapa."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import networkx as nx\n",
    "\n",
    "mapa = nx.Graph()\n",
    "mapa.add_edges_from(puntos)\n",
    "posicion = nx.spring_layout(mapa)\n",
    "nx.draw_networkx_nodes(mapa,posicion)\n",
    "nx.draw_networkx_edges(mapa,posicion)\n",
    "nx.draw_networkx_labels(mapa,posicion)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como podemos observar, el trayecto óptimo es bastante claro: (0, 1, 5, 7). La idea es que esa sea la ruta que Juan acabe tomando siempre para ir al trabajo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A continuación, creamos el gráfico de recompensas, el cual representaremos como una matriz R. Dado que nuestro mapa consta de 8 puntos, tendrá unas dimensiones de 8x8. Inicialmente los valores de la matriz serán todos -1. Sin embargo, a medida que se vayan tomando decisiones adecuadas estos variarán. En concreto, adoptarán el valor 0 si se escoge una ruta aceptable, y el valor 100 si se está siguiendo la ruta óptima."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "MATRIX_SIZE = 8\n",
    "\n",
    "R = np.matrix(np.ones(shape = (MATRIX_SIZE,MATRIX_SIZE)))\n",
    "R *= -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0, 1)\n",
      "(1, 2)\n",
      "(2, 3)\n",
      "(2, 4)\n",
      "(1, 5)\n",
      "(5, 6)\n",
      "(5, 7)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "matrix([[ -1.,   0.,  -1.,  -1.,  -1.,  -1.,  -1.,  -1.],\n",
       "        [  0.,  -1.,   0.,  -1.,  -1.,   0.,  -1.,  -1.],\n",
       "        [ -1.,   0.,  -1.,   0.,   0.,  -1.,  -1.,  -1.],\n",
       "        [ -1.,  -1.,   0.,  -1.,  -1.,  -1.,  -1.,  -1.],\n",
       "        [ -1.,  -1.,   0.,  -1.,  -1.,  -1.,  -1.,  -1.],\n",
       "        [ -1.,   0.,  -1.,  -1.,  -1.,  -1.,   0., 100.],\n",
       "        [ -1.,  -1.,  -1.,  -1.,  -1.,   0.,  -1.,  -1.],\n",
       "        [ -1.,  -1.,  -1.,  -1.,  -1.,   0.,  -1., 100.]])"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MATRIX_SIZE = 8\n",
    "R = np.matrix(np.ones(shape = (MATRIX_SIZE,MATRIX_SIZE)))\n",
    "R *= -1\n",
    "\n",
    "for punto in puntos:\n",
    "    print(punto)\n",
    "    if punto[1] == meta:\n",
    "        R[punto]=100\n",
    "    else:\n",
    "        R[punto]=0\n",
    "\n",
    "    if point[0] == meta:\n",
    "        R[punto[::-1]]=100\n",
    "    else:\n",
    "        R[punto[::-1]]=0\n",
    "\n",
    "R[meta,meta]= 100\n",
    "R"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A continuación, creamos la matriz Q y la función \"acciones_posibles\", la cual recogerá todos los movimientos posibles que Juan podrá hacer a partir de un punto de transbordo. Por ejemplo, en el punto 1 solo podrá ir al punto 2 o el punto 5. La matriz Q nos indicará cómo de buena es cada ruta tomada."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "Q = np.matrix(np.zeros([MATRIX_SIZE,MATRIX_SIZE]))\n",
    "\n",
    "gamma = 0.8\n",
    "\n",
    "estado_inicial = 1\n",
    "\n",
    "def acciones_posibles(state):\n",
    "    fila_estado_actual = R[state,]\n",
    "    av_accion = np.where(fila_estado_actual >= 0)[1]\n",
    "    return av_accion\n",
    "\n",
    "act_posible = acciones_posibles(estado_inicial)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La función \"proxima_accion\" genera una accion aleatoria."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "def proxima_accion(available_actions_range):\n",
    "    accion_elegida = int(np.random.choice(act_posible,1))\n",
    "    return accion_elegida\n",
    "\n",
    "action = proxima_accion(act_posible)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Por último, definimos la función \"update\" mediante la cual se irá actualizando la matriz de Q, acumulando valores en las distintas rutas, siendo las de mayor valor las que compongan la ruta óptima,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max_value 0.0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def update(estado_actual, action, gamma):\n",
    "\n",
    "  max_index = np.where(Q[action,] == np.max(Q[action,]))[1]\n",
    "\n",
    "  if max_index.shape[0] > 1:\n",
    "      max_index = int(np.random.choice(max_index, size = 1))\n",
    "  else:\n",
    "      max_index = int(max_index)\n",
    "  max_value = Q[action, max_index]\n",
    "\n",
    "  Q[estado_actual, action] = R[estado_actual, action] + gamma * max_value\n",
    "  print('max_value', R[estado_actual, action] + gamma * max_value)\n",
    "\n",
    "  if (np.max(Q) > 0):\n",
    "    return(np.sum(Q/np.max(Q)*100))\n",
    "  else:\n",
    "    return (0)\n",
    "\n",
    "update(estado_inicial, action, gamma)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creamos una funcion de training y de test.\n",
    "\n",
    "En el training, Juan realizará 1000 repeticiones con las 3 funciones anteriores, e incluirá una puntuación a cada repetición en función de lo buena que haya sido la ruta."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max_value 0.0\n",
      "Score: 0\n",
      "max_value 0.0\n",
      "Score: 0\n",
      "max_value 0.0\n",
      "Score: 0\n",
      "max_value 0.0\n",
      "Score: 0\n",
      "max_value 0.0\n",
      "Score: 0\n",
      "max_value 100.0\n",
      "Score: 100.0\n",
      "max_value 0.0\n",
      "Score: 100.0\n",
      "max_value 0.0\n",
      "Score: 100.0\n",
      "max_value 0.0\n",
      "Score: 100.0\n",
      "max_value 0.0\n",
      "Score: 100.0\n",
      "max_value 0.0\n",
      "Score: 100.0\n",
      "max_value 0.0\n",
      "Score: 100.0\n",
      "max_value 180.0\n",
      "Score: 100.0\n",
      "max_value 0.0\n",
      "Score: 100.0\n",
      "max_value 0.0\n",
      "Score: 100.0\n",
      "max_value 244.0\n",
      "Score: 173.77049180327867\n",
      "max_value 195.20000000000002\n",
      "Score: 253.77049180327867\n",
      "max_value 195.20000000000002\n",
      "Score: 253.77049180327867\n",
      "max_value 0.0\n",
      "Score: 253.77049180327867\n",
      "max_value 0.0\n",
      "Score: 253.77049180327867\n",
      "max_value 0.0\n",
      "Score: 253.77049180327867\n",
      "max_value 244.0\n",
      "Score: 253.77049180327867\n",
      "max_value 0.0\n",
      "Score: 253.77049180327867\n",
      "max_value 0.0\n",
      "Score: 253.77049180327867\n",
      "max_value 195.20000000000002\n",
      "Score: 333.7704918032787\n",
      "max_value 0.0\n",
      "Score: 333.7704918032787\n",
      "max_value 0.0\n",
      "Score: 333.7704918032787\n",
      "max_value 195.20000000000002\n",
      "Score: 333.7704918032787\n",
      "max_value 0.0\n",
      "Score: 333.7704918032787\n",
      "max_value 256.16\n",
      "Score: 322.6733291692692\n",
      "max_value 156.16000000000003\n",
      "Score: 383.63522798251097\n",
      "max_value 0.0\n",
      "Score: 383.63522798251097\n",
      "max_value 0.0\n",
      "Score: 383.63522798251097\n",
      "max_value 0.0\n",
      "Score: 383.63522798251097\n",
      "max_value 0.0\n",
      "Score: 383.63522798251097\n",
      "max_value 156.16000000000003\n",
      "Score: 383.63522798251097\n",
      "max_value 0.0\n",
      "Score: 383.63522798251097\n",
      "max_value 204.92800000000003\n",
      "Score: 387.43285446595877\n",
      "max_value 204.92800000000003\n",
      "Score: 387.43285446595877\n",
      "max_value 0.0\n",
      "Score: 387.43285446595877\n",
      "max_value 0.0\n",
      "Score: 387.43285446595877\n",
      "max_value 204.92800000000003\n",
      "Score: 387.43285446595877\n",
      "max_value 0.0\n",
      "Score: 387.43285446595877\n",
      "max_value 204.92800000000003\n",
      "Score: 387.43285446595877\n",
      "max_value 256.16\n",
      "Score: 387.43285446595877\n",
      "max_value 256.16\n",
      "Score: 387.43285446595877\n",
      "max_value 0.0\n",
      "Score: 387.43285446595877\n",
      "max_value 0.0\n",
      "Score: 387.43285446595877\n",
      "max_value 0.0\n",
      "Score: 387.43285446595877\n",
      "max_value 204.92800000000003\n",
      "Score: 387.43285446595877\n",
      "max_value 256.16\n",
      "Score: 417.1642723297939\n",
      "max_value 304.928\n",
      "Score: 366.4392905866303\n",
      "max_value 0.0\n",
      "Score: 366.4392905866303\n",
      "max_value 304.928\n",
      "Score: 382.4325742470354\n",
      "max_value 0.0\n",
      "Score: 382.4325742470354\n",
      "max_value 0.0\n",
      "Score: 382.4325742470354\n",
      "max_value 343.9424\n",
      "Score: 350.3954150462403\n",
      "max_value 0.0\n",
      "Score: 350.3954150462403\n",
      "max_value 0.0\n",
      "Score: 350.3954150462403\n",
      "max_value 275.15392\n",
      "Score: 370.8133454904077\n",
      "max_value 275.15392\n",
      "Score: 370.8133454904077\n",
      "max_value 0.0\n",
      "Score: 370.8133454904077\n",
      "max_value 275.15392\n",
      "Score: 394.05965650062336\n",
      "max_value 0.0\n",
      "Score: 394.05965650062336\n",
      "max_value 343.9424\n",
      "Score: 394.05965650062336\n",
      "max_value 275.15392\n",
      "Score: 394.05965650062336\n",
      "max_value 343.9424\n",
      "Score: 394.05965650062336\n",
      "max_value 0.0\n",
      "Score: 394.05965650062336\n",
      "max_value 0.0\n",
      "Score: 394.05965650062336\n",
      "max_value 0.0\n",
      "Score: 394.05965650062336\n",
      "max_value 343.9424\n",
      "Score: 405.40295119182747\n",
      "max_value 275.15392\n",
      "Score: 405.40295119182747\n",
      "max_value 275.15392\n",
      "Score: 405.40295119182747\n",
      "max_value 375.15392\n",
      "Score: 379.9944726687115\n",
      "max_value 0.0\n",
      "Score: 379.9944726687115\n",
      "max_value 0.0\n",
      "Score: 379.9944726687115\n",
      "max_value 0.0\n",
      "Score: 379.9944726687115\n",
      "max_value 0.0\n",
      "Score: 379.9944726687115\n",
      "max_value 400.12313600000004\n",
      "Score: 362.52174530592504\n",
      "max_value 0.0\n",
      "Score: 362.52174530592504\n",
      "max_value 275.15392\n",
      "Score: 362.52174530592504\n",
      "max_value 0.0\n",
      "Score: 362.52174530592504\n",
      "max_value 0.0\n",
      "Score: 362.52174530592504\n",
      "max_value 0.0\n",
      "Score: 362.52174530592504\n",
      "max_value 0.0\n",
      "Score: 362.52174530592504\n",
      "max_value 275.15392\n",
      "Score: 362.52174530592504\n",
      "max_value 0.0\n",
      "Score: 362.52174530592504\n",
      "max_value 0.0\n",
      "Score: 362.52174530592504\n",
      "max_value 220.12313600000004\n",
      "Score: 378.5076082178862\n",
      "max_value 0.0\n",
      "Score: 378.5076082178862\n",
      "max_value 420.09850880000005\n",
      "Score: 365.26477782155837\n",
      "max_value 0.0\n",
      "Score: 365.26477782155837\n",
      "max_value 0.0\n",
      "Score: 365.26477782155837\n",
      "max_value 275.15392\n",
      "Score: 430.7622538268815\n",
      "max_value 0.0\n",
      "Score: 430.7622538268815\n",
      "max_value 0.0\n",
      "Score: 430.7622538268815\n",
      "max_value 220.12313600000004\n",
      "Score: 483.16023463113993\n",
      "max_value 0.0\n",
      "Score: 483.16023463113993\n",
      "max_value 275.15392\n",
      "Score: 483.16023463113993\n",
      "max_value 0.0\n",
      "Score: 483.16023463113993\n",
      "max_value 436.0788070400001\n",
      "Score: 486.58300141730274\n",
      "max_value 0.0\n",
      "Score: 486.58300141730274\n",
      "max_value 0.0\n",
      "Score: 486.58300141730274\n",
      "max_value 220.12313600000004\n",
      "Score: 537.060835342355\n",
      "max_value 0.0\n",
      "Score: 537.060835342355\n",
      "max_value 0.0\n",
      "Score: 537.060835342355\n",
      "max_value 220.12313600000004\n",
      "Score: 537.060835342355\n",
      "max_value 0.0\n",
      "Score: 537.060835342355\n",
      "max_value 348.8630456320001\n",
      "Score: 553.9635429360396\n",
      "max_value 279.09043650560005\n",
      "Score: 567.4857090109874\n",
      "max_value 220.12313600000004\n",
      "Score: 567.4857090109874\n",
      "max_value 0.0\n",
      "Score: 567.4857090109874\n",
      "max_value 220.12313600000004\n",
      "Score: 567.4857090109874\n",
      "max_value 436.0788070400001\n",
      "Score: 567.4857090109874\n",
      "max_value 348.8630456320001\n",
      "Score: 584.3884166046722\n",
      "max_value 0.0\n",
      "Score: 584.3884166046722\n",
      "max_value 0.0\n",
      "Score: 584.3884166046722\n",
      "max_value 348.8630456320001\n",
      "Score: 584.3884166046722\n",
      "max_value 348.8630456320001\n",
      "Score: 601.291124198357\n",
      "max_value 0.0\n",
      "Score: 601.291124198357\n",
      "max_value 348.8630456320001\n",
      "Score: 601.291124198357\n",
      "max_value 348.8630456320001\n",
      "Score: 601.291124198357\n",
      "max_value 436.0788070400001\n",
      "Score: 601.291124198357\n",
      "max_value 436.0788070400001\n",
      "Score: 604.9556678501044\n",
      "max_value 0.0\n",
      "Score: 604.9556678501044\n",
      "max_value 0.0\n",
      "Score: 604.9556678501044\n",
      "max_value 448.8630456320001\n",
      "Score: 590.5738340168265\n",
      "max_value 348.8630456320001\n",
      "Score: 590.5738340168265\n",
      "max_value 279.09043650560005\n",
      "Score: 603.7108701527761\n",
      "max_value 459.0904365056001\n",
      "Score: 595.2741357119219\n",
      "max_value 367.2723492044801\n",
      "Score: 599.2840871525582\n",
      "max_value 367.2723492044801\n",
      "Score: 599.2840871525582\n",
      "max_value 367.2723492044801\n",
      "Score: 599.2840871525582\n",
      "max_value 0.0\n",
      "Score: 599.2840871525582\n",
      "max_value 293.8178793635841\n",
      "Score: 602.4920483050673\n",
      "max_value 0.0\n",
      "Score: 602.4920483050673\n",
      "max_value 293.8178793635841\n",
      "Score: 602.4920483050673\n",
      "max_value 367.2723492044801\n",
      "Score: 606.5019997457036\n",
      "max_value 0.0\n",
      "Score: 606.5019997457036\n",
      "max_value 279.09043650560005\n",
      "Score: 606.5019997457036\n",
      "max_value 0.0\n",
      "Score: 606.5019997457036\n",
      "max_value 0.0\n",
      "Score: 606.5019997457036\n",
      "max_value 367.2723492044801\n",
      "Score: 606.5019997457036\n",
      "max_value 367.2723492044801\n",
      "Score: 606.5019997457036\n",
      "max_value 279.09043650560005\n",
      "Score: 619.346375453992\n",
      "max_value 0.0\n",
      "Score: 619.346375453992\n",
      "max_value 0.0\n",
      "Score: 619.346375453992\n",
      "max_value 293.8178793635841\n",
      "Score: 619.346375453992\n",
      "max_value 0.0\n",
      "Score: 619.346375453992\n",
      "max_value 459.0904365056001\n",
      "Score: 619.346375453992\n",
      "max_value 279.09043650560005\n",
      "Score: 619.346375453992\n",
      "max_value 0.0\n",
      "Score: 619.346375453992\n",
      "max_value 0.0\n",
      "Score: 619.346375453992\n",
      "max_value 279.09043650560005\n",
      "Score: 619.346375453992\n",
      "max_value 367.2723492044801\n",
      "Score: 619.346375453992\n",
      "max_value 0.0\n",
      "Score: 619.346375453992\n",
      "max_value 279.09043650560005\n",
      "Score: 619.346375453992\n",
      "max_value 367.2723492044801\n",
      "Score: 623.3563268946283\n",
      "max_value 293.8178793635841\n",
      "Score: 687.3563268946283\n",
      "max_value 235.05430349086728\n",
      "Score: 738.5563268946282\n",
      "max_value 293.8178793635841\n",
      "Score: 741.7642880471374\n",
      "max_value 235.05430349086728\n",
      "Score: 741.7642880471374\n",
      "max_value 459.0904365056001\n",
      "Score: 743.9920388474909\n",
      "max_value 293.8178793635841\n",
      "Score: 743.9920388474909\n",
      "max_value 293.8178793635841\n",
      "Score: 743.9920388474909\n",
      "max_value 235.05430349086728\n",
      "Score: 795.192038847491\n",
      "max_value 367.2723492044801\n",
      "Score: 795.192038847491\n",
      "max_value 235.05430349086728\n",
      "Score: 846.392038847491\n",
      "max_value 367.2723492044801\n",
      "Score: 846.392038847491\n",
      "max_value 293.8178793635841\n",
      "Score: 846.392038847491\n",
      "max_value 293.8178793635841\n",
      "Score: 846.392038847491\n",
      "max_value 235.05430349086728\n",
      "Score: 846.392038847491\n",
      "max_value 467.2723492044801\n",
      "Score: 833.3227559948118\n",
      "max_value 235.05430349086728\n",
      "Score: 833.3227559948118\n",
      "max_value 188.04344279269384\n",
      "Score: 873.5655486858053\n",
      "max_value 235.05430349086728\n",
      "Score: 873.5655486858053\n",
      "max_value 293.8178793635841\n",
      "Score: 873.5655486858053\n",
      "max_value 367.2723492044801\n",
      "Score: 873.5655486858053\n",
      "max_value 293.8178793635841\n",
      "Score: 876.7173386179632\n",
      "max_value 367.2723492044801\n",
      "Score: 876.7173386179632\n",
      "max_value 367.2723492044801\n",
      "Score: 876.7173386179632\n",
      "max_value 235.05430349086728\n",
      "Score: 876.7173386179632\n",
      "max_value 473.8178793635841\n",
      "Score: 865.9874210980679\n",
      "max_value 367.2723492044801\n",
      "Score: 865.9874210980679\n",
      "max_value 293.8178793635841\n",
      "Score: 865.9874210980679\n",
      "max_value 293.8178793635841\n",
      "Score: 865.9874210980679\n",
      "max_value 235.05430349086728\n",
      "Score: 865.9874210980679\n",
      "max_value 367.2723492044801\n",
      "Score: 865.9874210980679\n",
      "max_value 235.05430349086728\n",
      "Score: 865.9874210980679\n",
      "max_value 235.05430349086728\n",
      "Score: 865.9874210980679\n",
      "max_value 235.05430349086728\n",
      "Score: 865.9874210980679\n",
      "max_value 235.05430349086728\n",
      "Score: 865.9874210980679\n",
      "max_value 188.04344279269384\n",
      "Score: 905.6742820171339\n",
      "max_value 293.8178793635841\n",
      "Score: 905.6742820171339\n",
      "max_value 479.0543034908673\n",
      "Score: 899.941929874012\n",
      "max_value 293.8178793635841\n",
      "Score: 899.941929874012\n",
      "max_value 383.2434427926939\n",
      "Score: 903.2758094513026\n",
      "max_value 235.05430349086728\n",
      "Score: 903.2758094513026\n",
      "max_value 293.8178793635841\n",
      "Score: 903.2758094513026\n",
      "max_value 383.2434427926939\n",
      "Score: 906.6096890285932\n",
      "max_value 306.5947542341551\n",
      "Score: 909.2767926904257\n",
      "max_value 235.05430349086728\n",
      "Score: 909.2767926904257\n",
      "max_value 306.5947542341551\n",
      "Score: 911.9438963522582\n",
      "max_value 306.5947542341551\n",
      "Score: 911.9438963522582\n",
      "max_value 306.5947542341551\n",
      "Score: 914.6110000140907\n",
      "max_value 245.27580338732412\n",
      "Score: 916.7446829435567\n",
      "max_value 245.27580338732412\n",
      "Score: 918.8783658730226\n",
      "max_value 196.2206427098593\n",
      "Score: 920.5853122165954\n",
      "max_value 383.2434427926939\n",
      "Score: 920.5853122165954\n",
      "max_value 245.27580338732412\n",
      "Score: 922.7189951460614\n",
      "max_value 245.27580338732412\n",
      "Score: 922.7189951460614\n",
      "max_value 306.5947542341551\n",
      "Score: 925.3860988078939\n",
      "max_value 245.27580338732412\n",
      "Score: 925.3860988078939\n",
      "max_value 306.5947542341551\n",
      "Score: 925.3860988078939\n",
      "max_value 306.5947542341551\n",
      "Score: 925.3860988078939\n",
      "max_value 245.27580338732412\n",
      "Score: 976.5860988078939\n",
      "max_value 383.2434427926939\n",
      "Score: 976.5860988078939\n",
      "max_value 383.2434427926939\n",
      "Score: 976.5860988078939\n",
      "max_value 245.27580338732412\n",
      "Score: 976.5860988078939\n",
      "max_value 245.27580338732412\n",
      "Score: 976.5860988078939\n",
      "max_value 383.2434427926939\n",
      "Score: 976.5860988078939\n",
      "max_value 245.27580338732412\n",
      "Score: 976.5860988078939\n",
      "max_value 479.0543034908673\n",
      "Score: 976.5860988078939\n",
      "max_value 245.27580338732412\n",
      "Score: 976.5860988078939\n",
      "max_value 479.0543034908673\n",
      "Score: 977.6791740791367\n",
      "max_value 245.27580338732412\n",
      "Score: 977.6791740791367\n",
      "max_value 245.27580338732412\n",
      "Score: 977.6791740791367\n",
      "max_value 483.2434427926939\n",
      "Score: 970.0707514975874\n",
      "max_value 306.5947542341551\n",
      "Score: 970.0707514975874\n",
      "max_value 383.2434427926939\n",
      "Score: 970.0707514975874\n",
      "max_value 306.5947542341551\n",
      "Score: 970.0707514975874\n",
      "max_value 245.27580338732412\n",
      "Score: 970.0707514975874\n",
      "max_value 245.27580338732412\n",
      "Score: 970.0707514975874\n",
      "max_value 306.5947542341551\n",
      "Score: 970.0707514975874\n",
      "max_value 486.5947542341551\n",
      "Score: 964.078335757381\n",
      "max_value 306.5947542341551\n",
      "Score: 964.078335757381\n",
      "max_value 306.5947542341551\n",
      "Score: 964.078335757381\n",
      "max_value 306.5947542341551\n",
      "Score: 964.078335757381\n",
      "max_value 383.2434427926939\n",
      "Score: 967.3605523142262\n",
      "max_value 489.2758033873241\n",
      "Score: 964.1488848067252\n",
      "max_value 245.27580338732412\n",
      "Score: 964.1488848067252\n",
      "max_value 306.5947542341551\n",
      "Score: 964.1488848067252\n",
      "max_value 245.27580338732412\n",
      "Score: 964.1488848067252\n",
      "max_value 489.2758033873241\n",
      "Score: 964.6968475579195\n",
      "max_value 245.27580338732412\n",
      "Score: 964.6968475579195\n",
      "max_value 306.5947542341551\n",
      "Score: 964.6968475579195\n",
      "max_value 306.5947542341551\n",
      "Score: 964.6968475579195\n",
      "max_value 391.4206427098593\n",
      "Score: 966.368133949062\n",
      "max_value 391.4206427098593\n",
      "Score: 968.0394203402044\n",
      "max_value 391.4206427098593\n",
      "Score: 968.0394203402044\n",
      "max_value 245.27580338732412\n",
      "Score: 968.0394203402044\n",
      "max_value 245.27580338732412\n",
      "Score: 968.0394203402044\n",
      "max_value 313.13651416788747\n",
      "Score: 969.3764494531184\n",
      "max_value 391.4206427098593\n",
      "Score: 969.3764494531184\n",
      "max_value 313.13651416788747\n",
      "Score: 970.7134785660323\n",
      "max_value 245.27580338732412\n",
      "Score: 970.7134785660323\n",
      "max_value 391.4206427098593\n",
      "Score: 972.3847649571749\n",
      "max_value 391.4206427098593\n",
      "Score: 972.3847649571749\n",
      "max_value 313.13651416788747\n",
      "Score: 972.3847649571749\n",
      "max_value 245.27580338732412\n",
      "Score: 972.3847649571749\n",
      "max_value 391.4206427098593\n",
      "Score: 972.3847649571749\n",
      "max_value 491.4206427098593\n",
      "Score: 968.5771814215245\n",
      "max_value 391.4206427098593\n",
      "Score: 968.5771814215245\n",
      "max_value 245.27580338732412\n",
      "Score: 968.5771814215245\n",
      "max_value 391.4206427098593\n",
      "Score: 968.5771814215245\n",
      "max_value 313.13651416788747\n",
      "Score: 968.5771814215245\n",
      "max_value 196.2206427098593\n",
      "Score: 970.2411733678282\n",
      "max_value 245.27580338732412\n",
      "Score: 970.2411733678282\n",
      "max_value 391.4206427098593\n",
      "Score: 970.2411733678282\n",
      "max_value 245.27580338732412\n",
      "Score: 970.2411733678282\n",
      "max_value 245.27580338732412\n",
      "Score: 970.2411733678282\n",
      "max_value 493.13651416788747\n",
      "Score: 967.6481022364255\n",
      "max_value 394.50921133431\n",
      "Score: 968.2744133157546\n",
      "max_value 394.50921133431\n",
      "Score: 968.9007243950837\n",
      "max_value 315.607369067448\n",
      "Score: 970.7283349196258\n",
      "max_value 394.50921133431\n",
      "Score: 970.7283349196258\n",
      "max_value 252.48589525395843\n",
      "Score: 972.1904233392596\n",
      "max_value 394.50921133431\n",
      "Score: 972.1904233392596\n",
      "max_value 201.98871620316675\n",
      "Score: 973.3600940749667\n",
      "max_value 252.48589525395843\n",
      "Score: 973.3600940749667\n",
      "max_value 394.50921133431\n",
      "Score: 973.9864051542958\n",
      "max_value 252.48589525395843\n",
      "Score: 975.4484935739296\n",
      "max_value 252.48589525395843\n",
      "Score: 975.4484935739296\n",
      "max_value 252.48589525395843\n",
      "Score: 975.4484935739296\n",
      "max_value 252.48589525395843\n",
      "Score: 975.4484935739296\n",
      "max_value 493.13651416788747\n",
      "Score: 975.4484935739296\n",
      "max_value 493.13651416788747\n",
      "Score: 975.4484935739296\n",
      "max_value 252.48589525395843\n",
      "Score: 976.9105819935634\n",
      "max_value 394.50921133431\n",
      "Score: 976.9105819935634\n",
      "max_value 493.13651416788747\n",
      "Score: 976.9105819935634\n",
      "max_value 315.607369067448\n",
      "Score: 977.4116308570266\n",
      "max_value 252.48589525395843\n",
      "Score: 977.4116308570266\n",
      "max_value 394.50921133431\n",
      "Score: 977.4116308570266\n",
      "max_value 252.48589525395843\n",
      "Score: 977.4116308570266\n",
      "max_value 394.50921133431\n",
      "Score: 977.4116308570266\n",
      "max_value 493.13651416788747\n",
      "Score: 977.4116308570266\n",
      "max_value 252.48589525395843\n",
      "Score: 977.4116308570266\n",
      "max_value 394.50921133431\n",
      "Score: 977.4116308570266\n",
      "max_value 252.48589525395843\n",
      "Score: 977.4116308570266\n",
      "max_value 394.50921133431\n",
      "Score: 977.4116308570266\n",
      "max_value 315.607369067448\n",
      "Score: 977.9126797204899\n",
      "max_value 394.50921133431\n",
      "Score: 977.9126797204899\n",
      "max_value 252.48589525395843\n",
      "Score: 977.9126797204899\n",
      "max_value 252.48589525395843\n",
      "Score: 977.9126797204899\n",
      "max_value 252.48589525395843\n",
      "Score: 977.9126797204899\n",
      "max_value 394.50921133431\n",
      "Score: 977.9126797204899\n",
      "max_value 252.48589525395843\n",
      "Score: 977.9126797204899\n",
      "max_value 252.48589525395843\n",
      "Score: 979.3747681401237\n",
      "max_value 252.48589525395843\n",
      "Score: 979.3747681401237\n",
      "max_value 394.50921133431\n",
      "Score: 979.3747681401237\n",
      "max_value 315.607369067448\n",
      "Score: 979.3747681401237\n",
      "max_value 394.50921133431\n",
      "Score: 979.3747681401237\n",
      "max_value 315.607369067448\n",
      "Score: 979.3747681401237\n",
      "max_value 493.13651416788747\n",
      "Score: 979.3747681401237\n",
      "max_value 252.48589525395843\n",
      "Score: 979.3747681401237\n",
      "max_value 315.607369067448\n",
      "Score: 979.3747681401237\n",
      "max_value 493.13651416788747\n",
      "Score: 979.7227187397509\n",
      "max_value 201.98871620316675\n",
      "Score: 980.8923894754579\n",
      "max_value 315.607369067448\n",
      "Score: 980.8923894754579\n",
      "max_value 394.50921133431\n",
      "Score: 980.8923894754579\n",
      "max_value 315.607369067448\n",
      "Score: 980.8923894754579\n",
      "max_value 252.48589525395843\n",
      "Score: 980.8923894754579\n",
      "max_value 252.48589525395843\n",
      "Score: 980.8923894754579\n",
      "max_value 201.98871620316675\n",
      "Score: 980.8923894754579\n",
      "max_value 394.50921133431\n",
      "Score: 980.8923894754579\n",
      "max_value 315.607369067448\n",
      "Score: 980.8923894754579\n",
      "max_value 494.50921133431\n",
      "Score: 978.4471398031749\n",
      "max_value 252.48589525395843\n",
      "Score: 978.4471398031749\n",
      "max_value 252.48589525395843\n",
      "Score: 978.4471398031749\n",
      "max_value 252.48589525395843\n",
      "Score: 978.4471398031749\n",
      "max_value 315.607369067448\n",
      "Score: 980.2696771041433\n",
      "max_value 252.48589525395843\n",
      "Score: 980.2696771041433\n",
      "max_value 252.48589525395843\n",
      "Score: 980.2696771041433\n",
      "max_value 315.607369067448\n",
      "Score: 980.2696771041433\n",
      "max_value 494.50921133431\n",
      "Score: 980.2696771041433\n",
      "max_value 252.48589525395843\n",
      "Score: 980.2696771041433\n",
      "max_value 252.48589525395843\n",
      "Score: 980.2696771041433\n",
      "max_value 252.48589525395843\n",
      "Score: 980.2696771041433\n",
      "max_value 395.607369067448\n",
      "Score: 980.4917473321527\n",
      "max_value 252.48589525395843\n",
      "Score: 980.4917473321527\n",
      "max_value 494.50921133431\n",
      "Score: 980.7693351171647\n",
      "max_value 395.607369067448\n",
      "Score: 980.7693351171647\n",
      "max_value 495.607369067448\n",
      "Score: 978.8177425524905\n",
      "max_value 496.48589525395846\n",
      "Score: 977.26268447857\n",
      "max_value 315.607369067448\n",
      "Score: 977.26268447857\n",
      "max_value 395.607369067448\n",
      "Score: 977.26268447857\n",
      "max_value 252.48589525395843\n",
      "Score: 977.26268447857\n",
      "max_value 201.98871620316675\n",
      "Score: 977.26268447857\n",
      "max_value 316.48589525395846\n",
      "Score: 977.4396333496072\n",
      "max_value 252.48589525395843\n",
      "Score: 977.4396333496072\n",
      "max_value 252.48589525395843\n",
      "Score: 977.4396333496072\n",
      "max_value 315.607369067448\n",
      "Score: 977.4396333496072\n",
      "max_value 395.607369067448\n",
      "Score: 977.4396333496072\n",
      "max_value 497.1887162031668\n",
      "Score: 976.5968657035135\n",
      "max_value 201.98871620316675\n",
      "Score: 976.5968657035135\n",
      "max_value 497.1887162031668\n",
      "Score: 976.7382246938332\n",
      "max_value 497.75097296253347\n",
      "Score: 975.7478660209102\n",
      "max_value 316.48589525395846\n",
      "Score: 975.7478660209102\n",
      "max_value 315.607369067448\n",
      "Score: 975.7478660209102\n",
      "max_value 315.607369067448\n",
      "Score: 975.7478660209102\n",
      "max_value 315.607369067448\n",
      "Score: 975.7478660209102\n",
      "max_value 201.98871620316675\n",
      "Score: 975.7478660209102\n",
      "max_value 315.607369067448\n",
      "Score: 975.7478660209102\n",
      "max_value 252.48589525395843\n",
      "Score: 975.7478660209102\n",
      "max_value 398.2007783700268\n",
      "Score: 976.4895154070972\n",
      "max_value 398.2007783700268\n",
      "Score: 977.010540868312\n",
      "max_value 252.48589525395843\n",
      "Score: 977.010540868312\n",
      "max_value 497.75097296253347\n",
      "Score: 977.010540868312\n",
      "max_value 398.2007783700268\n",
      "Score: 977.010540868312\n",
      "max_value 497.75097296253347\n",
      "Score: 977.010540868312\n",
      "max_value 315.607369067448\n",
      "Score: 977.010540868312\n",
      "max_value 318.5606226960215\n",
      "Score: 977.4273612372837\n",
      "max_value 497.75097296253347\n",
      "Score: 977.4273612372837\n",
      "max_value 497.75097296253347\n",
      "Score: 977.4273612372837\n",
      "max_value 318.5606226960215\n",
      "Score: 977.4273612372837\n",
      "max_value 398.2007783700268\n",
      "Score: 977.4273612372837\n",
      "max_value 398.2007783700268\n",
      "Score: 978.1690106234709\n",
      "max_value 318.5606226960215\n",
      "Score: 978.7623301324205\n",
      "max_value 318.5606226960215\n",
      "Score: 979.3556496413702\n",
      "max_value 318.5606226960215\n",
      "Score: 979.3556496413702\n",
      "max_value 252.48589525395843\n",
      "Score: 979.3556496413702\n",
      "max_value 201.98871620316675\n",
      "Score: 979.3556496413702\n",
      "max_value 318.5606226960215\n",
      "Score: 979.9489691503198\n",
      "max_value 497.75097296253347\n",
      "Score: 979.9489691503198\n",
      "max_value 201.98871620316675\n",
      "Score: 979.9489691503198\n",
      "max_value 318.5606226960215\n",
      "Score: 979.9489691503198\n",
      "max_value 254.8484981568172\n",
      "Score: 980.4236247574796\n",
      "max_value 254.8484981568172\n",
      "Score: 980.8982803646393\n",
      "max_value 398.2007783700268\n",
      "Score: 980.8982803646393\n",
      "max_value 398.2007783700268\n",
      "Score: 980.8982803646393\n",
      "max_value 497.75097296253347\n",
      "Score: 981.0112398142251\n",
      "max_value 398.2007783700268\n",
      "Score: 981.0112398142251\n",
      "max_value 318.5606226960215\n",
      "Score: 981.0112398142251\n",
      "max_value 398.2007783700268\n",
      "Score: 981.0112398142251\n",
      "max_value 254.8484981568172\n",
      "Score: 981.0112398142251\n",
      "max_value 254.8484981568172\n",
      "Score: 981.4858954213848\n",
      "max_value 318.5606226960215\n",
      "Score: 981.4858954213848\n",
      "max_value 498.2007783700268\n",
      "Score: 980.6900373264078\n",
      "max_value 254.8484981568172\n",
      "Score: 980.6900373264078\n",
      "max_value 318.5606226960215\n",
      "Score: 980.6900373264078\n",
      "max_value 498.5606226960215\n",
      "Score: 980.0543848130219\n",
      "max_value 498.8484981568172\n",
      "Score: 979.7088268152702\n",
      "max_value 318.5606226960215\n",
      "Score: 979.7088268152702\n",
      "max_value 254.8484981568172\n",
      "Score: 979.7088268152702\n",
      "max_value 399.07879852545375\n",
      "Score: 979.8848361966096\n",
      "max_value 203.87879852545376\n",
      "Score: 980.2637252439398\n",
      "max_value 318.5606226960215\n",
      "Score: 980.2637252439398\n",
      "max_value 399.07879852545375\n",
      "Score: 980.4397346252792\n",
      "max_value 318.5606226960215\n",
      "Score: 980.4397346252792\n",
      "max_value 399.07879852545375\n",
      "Score: 980.4397346252792\n",
      "max_value 254.8484981568172\n",
      "Score: 980.4397346252792\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max_value 203.87879852545376\n",
      "Score: 980.4397346252792\n",
      "max_value 318.5606226960215\n",
      "Score: 980.4397346252792\n",
      "max_value 399.07879852545375\n",
      "Score: 980.4397346252792\n",
      "max_value 203.87879852545376\n",
      "Score: 980.8186236726094\n",
      "max_value 498.8484981568172\n",
      "Score: 980.8763316664912\n",
      "max_value 399.07879852545375\n",
      "Score: 980.8763316664912\n",
      "max_value 499.07879852545375\n",
      "Score: 980.4698504765361\n",
      "max_value 254.8484981568172\n",
      "Score: 980.4698504765361\n",
      "max_value 399.07879852545375\n",
      "Score: 980.4698504765361\n",
      "max_value 318.5606226960215\n",
      "Score: 980.4698504765361\n",
      "max_value 254.8484981568172\n",
      "Score: 980.9432432373263\n",
      "max_value 399.07879852545375\n",
      "Score: 980.9432432373263\n",
      "max_value 399.07879852545375\n",
      "Score: 980.9432432373263\n",
      "max_value 254.8484981568172\n",
      "Score: 980.9432432373263\n",
      "max_value 399.07879852545375\n",
      "Score: 980.9432432373263\n",
      "max_value 254.8484981568172\n",
      "Score: 980.9432432373263\n",
      "max_value 399.07879852545375\n",
      "Score: 980.9432432373263\n",
      "max_value 499.263038820363\n",
      "Score: 980.6181535945683\n",
      "max_value 203.87879852545376\n",
      "Score: 980.6181535945683\n",
      "max_value 399.07879852545375\n",
      "Score: 980.7940168344152\n",
      "max_value 499.41043105629046\n",
      "Score: 980.6170719256127\n",
      "max_value 319.263038820363\n",
      "Score: 980.7577209951278\n",
      "max_value 254.8484981568172\n",
      "Score: 980.7577209951278\n",
      "max_value 399.5283448450324\n",
      "Score: 980.8477363996174\n",
      "max_value 319.62267587602594\n",
      "Score: 981.0603977927242\n",
      "max_value 254.8484981568172\n",
      "Score: 981.0603977927242\n",
      "max_value 319.263038820363\n",
      "Score: 981.2010468622391\n",
      "max_value 255.41043105629043\n",
      "Score: 981.3135661178511\n",
      "max_value 203.87879852545376\n",
      "Score: 981.3135661178511\n",
      "max_value 399.5283448450324\n",
      "Score: 981.4035815223407\n",
      "max_value 319.62267587602594\n",
      "Score: 981.6162429154474\n",
      "max_value 203.87879852545376\n",
      "Score: 981.6162429154474\n",
      "max_value 255.41043105629043\n",
      "Score: 981.7287621710594\n",
      "max_value 319.62267587602594\n",
      "Score: 981.7287621710594\n",
      "max_value 255.41043105629043\n",
      "Score: 981.7287621710594\n",
      "max_value 319.62267587602594\n",
      "Score: 981.8007744946511\n",
      "max_value 255.41043105629043\n",
      "Score: 981.9132937502632\n",
      "max_value 319.62267587602594\n",
      "Score: 981.9132937502632\n",
      "max_value 204.32834484503235\n",
      "Score: 982.0033091547527\n",
      "max_value 255.41043105629043\n",
      "Score: 982.0033091547527\n",
      "max_value 319.62267587602594\n",
      "Score: 982.0753214783444\n",
      "max_value 255.69814070082077\n",
      "Score: 982.1329313372178\n",
      "max_value 499.41043105629046\n",
      "Score: 982.1329313372178\n",
      "max_value 255.69814070082077\n",
      "Score: 982.3030604517032\n",
      "max_value 399.5283448450324\n",
      "Score: 982.3030604517032\n",
      "max_value 399.5283448450324\n",
      "Score: 982.3030604517032\n",
      "max_value 319.62267587602594\n",
      "Score: 982.3030604517032\n",
      "max_value 399.5283448450324\n",
      "Score: 982.3030604517032\n",
      "max_value 499.41043105629046\n",
      "Score: 982.3325736990769\n",
      "max_value 399.5283448450324\n",
      "Score: 982.3325736990769\n",
      "max_value 319.62267587602594\n",
      "Score: 982.3325736990769\n",
      "max_value 319.62267587602594\n",
      "Score: 982.3325736990769\n",
      "max_value 319.62267587602594\n",
      "Score: 982.3325736990769\n",
      "max_value 399.5283448450324\n",
      "Score: 982.3325736990769\n",
      "max_value 319.62267587602594\n",
      "Score: 982.3325736990769\n",
      "max_value 319.62267587602594\n",
      "Score: 982.3325736990769\n",
      "max_value 319.62267587602594\n",
      "Score: 982.3325736990769\n",
      "max_value 319.62267587602594\n",
      "Score: 982.3325736990769\n",
      "max_value 255.69814070082077\n",
      "Score: 982.3901835579502\n",
      "max_value 255.69814070082077\n",
      "Score: 982.3901835579502\n",
      "max_value 399.5283448450324\n",
      "Score: 982.3901835579502\n",
      "max_value 499.5283448450324\n",
      "Score: 982.1818951379521\n",
      "max_value 499.5283448450324\n",
      "Score: 982.1818951379521\n",
      "max_value 255.69814070082077\n",
      "Score: 982.2394913980041\n",
      "max_value 399.62267587602594\n",
      "Score: 982.2583754176933\n",
      "max_value 255.69814070082077\n",
      "Score: 982.2583754176933\n",
      "max_value 319.62267587602594\n",
      "Score: 982.2583754176933\n",
      "max_value 399.62267587602594\n",
      "Score: 982.2583754176933\n",
      "max_value 399.62267587602594\n",
      "Score: 982.2772594373824\n",
      "max_value 255.69814070082077\n",
      "Score: 982.2772594373824\n",
      "max_value 204.55851256065662\n",
      "Score: 982.4133306017553\n",
      "max_value 319.6981407008208\n",
      "Score: 982.4284378175066\n",
      "max_value 499.5283448450324\n",
      "Score: 982.4520428421181\n",
      "max_value 204.55851256065662\n",
      "Score: 982.4520428421181\n",
      "max_value 399.62267587602594\n",
      "Score: 982.5609210181385\n",
      "max_value 255.69814070082077\n",
      "Score: 982.5609210181385\n",
      "max_value 255.69814070082077\n",
      "Score: 982.5609210181385\n",
      "max_value 255.75851256065664\n",
      "Score: 982.5730067907397\n",
      "max_value 319.6981407008208\n",
      "Score: 982.5881140064909\n",
      "max_value 255.69814070082077\n",
      "Score: 982.5881140064909\n",
      "max_value 319.6981407008208\n",
      "Score: 982.6032212222422\n",
      "max_value 399.62267587602594\n",
      "Score: 982.6032212222422\n",
      "max_value 319.6981407008208\n",
      "Score: 982.6032212222422\n",
      "max_value 255.69814070082077\n",
      "Score: 982.6032212222422\n",
      "max_value 255.69814070082077\n",
      "Score: 982.6032212222422\n",
      "max_value 255.69814070082077\n",
      "Score: 982.6032212222422\n",
      "max_value 399.62267587602594\n",
      "Score: 982.6032212222422\n",
      "max_value 255.69814070082077\n",
      "Score: 982.6032212222422\n",
      "max_value 255.69814070082077\n",
      "Score: 982.6032212222422\n",
      "max_value 399.62267587602594\n",
      "Score: 982.6032212222422\n",
      "max_value 319.6981407008208\n",
      "Score: 982.6032212222422\n",
      "max_value 204.55851256065662\n",
      "Score: 982.6032212222422\n",
      "max_value 255.75851256065664\n",
      "Score: 982.6032212222422\n",
      "max_value 319.6981407008208\n",
      "Score: 982.6032212222422\n",
      "max_value 399.62267587602594\n",
      "Score: 982.6032212222422\n",
      "max_value 319.6981407008208\n",
      "Score: 982.6032212222422\n",
      "max_value 255.69814070082077\n",
      "Score: 982.6032212222422\n",
      "max_value 319.6981407008208\n",
      "Score: 982.6032212222422\n",
      "max_value 319.6981407008208\n",
      "Score: 982.6032212222422\n",
      "max_value 399.62267587602594\n",
      "Score: 982.6032212222422\n",
      "max_value 319.6981407008208\n",
      "Score: 982.6183284379936\n",
      "max_value 319.6981407008208\n",
      "Score: 982.6183284379936\n",
      "max_value 319.6981407008208\n",
      "Score: 982.6183284379936\n",
      "max_value 319.6981407008208\n",
      "Score: 982.6183284379936\n",
      "max_value 319.6981407008208\n",
      "Score: 982.6183284379936\n",
      "max_value 399.62267587602594\n",
      "Score: 982.6183284379936\n",
      "max_value 499.62267587602594\n",
      "Score: 982.4516860878452\n",
      "max_value 204.55851256065662\n",
      "Score: 982.4516860878452\n",
      "max_value 499.62267587602594\n",
      "Score: 982.4516860878452\n",
      "max_value 319.6981407008208\n",
      "Score: 982.4516860878452\n",
      "max_value 399.6981407008208\n",
      "Score: 982.4667904512858\n",
      "max_value 255.75851256065664\n",
      "Score: 982.478873942038\n",
      "max_value 319.6981407008208\n",
      "Score: 982.478873942038\n",
      "max_value 204.55851256065662\n",
      "Score: 982.5249422505311\n",
      "max_value 399.6981407008208\n",
      "Score: 982.5400466139714\n",
      "max_value 204.55851256065662\n",
      "Score: 982.5400466139714\n",
      "max_value 255.75851256065664\n",
      "Score: 982.5400466139714\n",
      "max_value 255.75851256065664\n",
      "Score: 982.5521301047238\n",
      "max_value 319.6981407008208\n",
      "Score: 982.5521301047238\n",
      "max_value 255.75851256065664\n",
      "Score: 982.5642135954761\n",
      "max_value 399.6981407008208\n",
      "Score: 982.5642135954761\n",
      "max_value 319.6981407008208\n",
      "Score: 982.5642135954761\n",
      "max_value 255.75851256065664\n",
      "Score: 982.5642135954761\n",
      "max_value 399.6981407008208\n",
      "Score: 982.5642135954761\n",
      "max_value 399.6981407008208\n",
      "Score: 982.5642135954761\n",
      "max_value 255.75851256065664\n",
      "Score: 982.5642135954761\n",
      "max_value 319.6981407008208\n",
      "Score: 982.5642135954761\n",
      "max_value 319.6981407008208\n",
      "Score: 982.5642135954761\n",
      "max_value 399.6981407008208\n",
      "Score: 982.5642135954761\n",
      "max_value 204.60681004852532\n",
      "Score: 982.5738803880779\n",
      "max_value 319.6981407008208\n",
      "Score: 982.5738803880779\n",
      "max_value 319.6981407008208\n",
      "Score: 982.5738803880779\n",
      "max_value 399.6981407008208\n",
      "Score: 982.5738803880779\n",
      "max_value 255.75851256065664\n",
      "Score: 982.5738803880779\n",
      "max_value 319.6981407008208\n",
      "Score: 982.5738803880779\n",
      "max_value 255.75851256065664\n",
      "Score: 982.5738803880779\n",
      "max_value 255.75851256065664\n",
      "Score: 982.5738803880779\n",
      "max_value 255.75851256065664\n",
      "Score: 982.5738803880779\n",
      "max_value 255.75851256065664\n",
      "Score: 982.5738803880779\n",
      "max_value 399.6981407008208\n",
      "Score: 982.5738803880779\n",
      "max_value 319.6981407008208\n",
      "Score: 982.5738803880779\n",
      "max_value 399.6981407008208\n",
      "Score: 982.5738803880779\n",
      "max_value 255.75851256065664\n",
      "Score: 982.5738803880779\n",
      "max_value 255.75851256065664\n",
      "Score: 982.5738803880779\n",
      "max_value 255.75851256065664\n",
      "Score: 982.5738803880779\n",
      "max_value 255.75851256065664\n",
      "Score: 982.5738803880779\n",
      "max_value 319.6981407008208\n",
      "Score: 982.5738803880779\n",
      "max_value 319.6981407008208\n",
      "Score: 982.5738803880779\n",
      "max_value 399.6981407008208\n",
      "Score: 982.5738803880779\n",
      "max_value 399.6981407008208\n",
      "Score: 982.5738803880779\n",
      "max_value 319.6981407008208\n",
      "Score: 982.5738803880779\n",
      "max_value 319.6981407008208\n",
      "Score: 982.5738803880779\n",
      "max_value 255.75851256065664\n",
      "Score: 982.5738803880779\n",
      "max_value 399.6981407008208\n",
      "Score: 982.5738803880779\n",
      "max_value 255.75851256065664\n",
      "Score: 982.5738803880779\n",
      "max_value 319.6981407008208\n",
      "Score: 982.5738803880779\n",
      "max_value 319.6981407008208\n",
      "Score: 982.5738803880779\n",
      "max_value 319.6981407008208\n",
      "Score: 982.5738803880779\n",
      "max_value 319.6981407008208\n",
      "Score: 982.5738803880779\n",
      "max_value 499.62267587602594\n",
      "Score: 982.5738803880779\n",
      "max_value 399.6981407008208\n",
      "Score: 982.5738803880779\n",
      "max_value 399.6981407008208\n",
      "Score: 982.5738803880779\n",
      "max_value 255.75851256065664\n",
      "Score: 982.5738803880779\n",
      "max_value 255.75851256065664\n",
      "Score: 982.5738803880779\n",
      "max_value 319.6981407008208\n",
      "Score: 982.5738803880779\n",
      "max_value 399.6981407008208\n",
      "Score: 982.5738803880779\n",
      "max_value 499.62267587602594\n",
      "Score: 982.5738803880779\n",
      "max_value 319.6981407008208\n",
      "Score: 982.5738803880779\n",
      "max_value 399.6981407008208\n",
      "Score: 982.5889847515184\n",
      "max_value 255.75851256065664\n",
      "Score: 982.5889847515184\n",
      "max_value 499.62267587602594\n",
      "Score: 982.6078652058188\n",
      "max_value 204.60681004852532\n",
      "Score: 982.6078652058188\n",
      "max_value 255.75851256065664\n",
      "Score: 982.6078652058188\n",
      "max_value 204.60681004852532\n",
      "Score: 982.6078652058188\n",
      "max_value 319.75851256065664\n",
      "Score: 982.6199486965711\n",
      "max_value 319.75851256065664\n",
      "Score: 982.6320321873234\n",
      "max_value 255.75851256065664\n",
      "Score: 982.6320321873234\n",
      "max_value 255.75851256065664\n",
      "Score: 982.6320321873234\n",
      "max_value 204.60681004852532\n",
      "Score: 982.6320321873234\n",
      "max_value 255.75851256065664\n",
      "Score: 982.6320321873234\n",
      "max_value 399.6981407008208\n",
      "Score: 982.6320321873234\n",
      "max_value 319.75851256065664\n",
      "Score: 982.6320321873234\n",
      "max_value 204.60681004852532\n",
      "Score: 982.6416989799252\n",
      "max_value 255.75851256065664\n",
      "Score: 982.6416989799252\n",
      "max_value 399.6981407008208\n",
      "Score: 982.6416989799252\n",
      "max_value 255.75851256065664\n",
      "Score: 982.6416989799252\n",
      "max_value 204.60681004852532\n",
      "Score: 982.6416989799252\n",
      "max_value 204.60681004852532\n",
      "Score: 982.6416989799252\n",
      "max_value 499.6981407008208\n",
      "Score: 982.5084017035401\n",
      "max_value 204.60681004852532\n",
      "Score: 982.5084017035401\n",
      "max_value 319.75851256065664\n",
      "Score: 982.5204833694337\n",
      "max_value 255.80681004852534\n",
      "Score: 982.5301487021486\n",
      "max_value 319.75851256065664\n",
      "Score: 982.542230368042\n",
      "max_value 499.75851256065664\n",
      "Score: 982.4356174450165\n",
      "max_value 399.6981407008208\n",
      "Score: 982.4356174450165\n",
      "max_value 319.75851256065664\n",
      "Score: 982.4356174450165\n",
      "max_value 255.80681004852534\n",
      "Score: 982.4452816101392\n",
      "max_value 255.80681004852534\n",
      "Score: 982.4452816101392\n",
      "max_value 255.80681004852534\n",
      "Score: 982.4452816101392\n",
      "max_value 255.80681004852534\n",
      "Score: 982.4549457752619\n",
      "max_value 399.6981407008208\n",
      "Score: 982.4549457752619\n",
      "max_value 255.80681004852534\n",
      "Score: 982.4549457752619\n",
      "max_value 255.80681004852534\n",
      "Score: 982.4549457752619\n",
      "max_value 255.80681004852534\n",
      "Score: 982.4549457752619\n",
      "max_value 399.6981407008208\n",
      "Score: 982.4549457752619\n",
      "max_value 499.80681004852534\n",
      "Score: 982.3968499510527\n",
      "max_value 255.80681004852534\n",
      "Score: 982.3968499510527\n",
      "max_value 399.8454480388203\n",
      "Score: 982.4263228063716\n",
      "max_value 255.80681004852534\n",
      "Score: 982.4263228063716\n",
      "max_value 319.75851256065664\n",
      "Score: 982.4263228063716\n",
      "max_value 399.8454480388203\n",
      "Score: 982.4557956616904\n",
      "max_value 255.80681004852534\n",
      "Score: 982.4557956616904\n",
      "max_value 255.80681004852534\n",
      "Score: 982.4557956616904\n",
      "max_value 319.75851256065664\n",
      "Score: 982.4557956616904\n",
      "max_value 499.80681004852534\n",
      "Score: 982.4654588929425\n",
      "max_value 204.6454480388203\n",
      "Score: 982.4731894779441\n",
      "max_value 255.80681004852534\n",
      "Score: 982.4731894779441\n",
      "max_value 399.8454480388203\n",
      "Score: 982.4731894779441\n",
      "max_value 399.8454480388203\n",
      "Score: 982.4731894779441\n",
      "max_value 399.8454480388203\n",
      "Score: 982.4731894779441\n",
      "max_value 255.80681004852534\n",
      "Score: 982.4731894779441\n",
      "max_value 255.80681004852534\n",
      "Score: 982.4731894779441\n",
      "max_value 399.8454480388203\n",
      "Score: 982.5026623332631\n",
      "max_value 499.8454480388203\n",
      "Score: 982.434444988409\n",
      "max_value 499.8454480388203\n",
      "Score: 982.434444988409\n",
      "max_value 319.87635843105625\n",
      "Score: 982.4580214500658\n",
      "max_value 399.87635843105625\n",
      "Score: 982.4642054400086\n",
      "max_value 319.87635843105625\n",
      "Score: 982.4642054400086\n",
      "max_value 319.87635843105625\n",
      "Score: 982.4642054400086\n",
      "max_value 499.8454480388203\n",
      "Score: 982.4642054400086\n",
      "max_value 255.80681004852534\n",
      "Score: 982.4642054400086\n",
      "max_value 255.80681004852534\n",
      "Score: 982.4642054400086\n",
      "max_value 255.80681004852534\n",
      "Score: 982.4738679242942\n",
      "max_value 255.80681004852534\n",
      "Score: 982.4738679242942\n",
      "max_value 499.8454480388203\n",
      "Score: 982.4738679242942\n",
      "max_value 399.87635843105625\n",
      "Score: 982.4800519142368\n",
      "max_value 399.87635843105625\n",
      "Score: 982.4800519142368\n",
      "max_value 255.80681004852534\n",
      "Score: 982.4800519142368\n",
      "max_value 255.80681004852534\n",
      "Score: 982.4800519142368\n",
      "max_value 319.90108674484503\n",
      "Score: 982.5085755678476\n",
      "max_value 319.87635843105625\n",
      "Score: 982.5085755678476\n",
      "max_value 204.6454480388203\n",
      "Score: 982.5163055552762\n",
      "max_value 399.87635843105625\n",
      "Score: 982.5163055552762\n",
      "max_value 399.87635843105625\n",
      "Score: 982.5163055552762\n",
      "max_value 399.87635843105625\n",
      "Score: 982.5163055552762\n",
      "max_value 319.87635843105625\n",
      "Score: 982.5398820169329\n",
      "max_value 319.87635843105625\n",
      "Score: 982.5398820169329\n",
      "max_value 319.87635843105625\n",
      "Score: 982.5398820169329\n",
      "max_value 255.80681004852534\n",
      "Score: 982.5398820169329\n",
      "max_value 399.87635843105625\n",
      "Score: 982.5460660068755\n",
      "max_value 399.87635843105625\n",
      "Score: 982.5460660068755\n",
      "max_value 204.6454480388203\n",
      "Score: 982.5460660068755\n",
      "max_value 399.87635843105625\n",
      "Score: 982.5460660068755\n",
      "max_value 255.80681004852534\n",
      "Score: 982.5460660068755\n",
      "max_value 399.87635843105625\n",
      "Score: 982.5460660068755\n",
      "max_value 399.87635843105625\n",
      "Score: 982.5460660068755\n",
      "max_value 399.87635843105625\n",
      "Score: 982.5460660068755\n",
      "max_value 255.80681004852534\n",
      "Score: 982.5460660068755\n",
      "max_value 255.80681004852534\n",
      "Score: 982.5460660068755\n",
      "max_value 319.90108674484503\n",
      "Score: 982.5460660068755\n",
      "max_value 399.87635843105625\n",
      "Score: 982.5460660068755\n",
      "max_value 204.6454480388203\n",
      "Score: 982.5460660068755\n",
      "max_value 255.80681004852534\n",
      "Score: 982.5460660068755\n",
      "max_value 255.80681004852534\n",
      "Score: 982.5460660068755\n",
      "max_value 204.6454480388203\n",
      "Score: 982.5460660068755\n",
      "max_value 399.87635843105625\n",
      "Score: 982.5460660068755\n",
      "max_value 319.90108674484503\n",
      "Score: 982.5510131988298\n",
      "max_value 255.80681004852534\n",
      "Score: 982.5510131988298\n",
      "max_value 319.90108674484503\n",
      "Score: 982.555960390784\n",
      "max_value 319.90108674484503\n",
      "Score: 982.555960390784\n",
      "max_value 255.80681004852534\n",
      "Score: 982.555960390784\n",
      "max_value 499.8454480388203\n",
      "Score: 982.555960390784\n",
      "max_value 319.90108674484503\n",
      "Score: 982.555960390784\n",
      "max_value 399.87635843105625\n",
      "Score: 982.555960390784\n",
      "max_value 499.8454480388203\n",
      "Score: 982.555960390784\n",
      "max_value 255.80681004852534\n",
      "Score: 982.555960390784\n",
      "max_value 319.90108674484503\n",
      "Score: 982.5844840443949\n",
      "max_value 499.8454480388203\n",
      "Score: 982.5844840443949\n",
      "max_value 255.92086939587603\n",
      "Score: 982.6073029672837\n",
      "max_value 399.87635843105625\n",
      "Score: 982.6073029672837\n",
      "max_value 255.92086939587603\n",
      "Score: 982.6301218901723\n",
      "max_value 399.87635843105625\n",
      "Score: 982.6301218901723\n",
      "max_value 319.90108674484503\n",
      "Score: 982.6301218901723\n",
      "max_value 255.92086939587603\n",
      "Score: 982.6301218901723\n",
      "max_value 319.90108674484503\n",
      "Score: 982.6301218901723\n",
      "max_value 319.90108674484503\n",
      "Score: 982.6301218901723\n",
      "max_value 319.90108674484503\n",
      "Score: 982.6301218901723\n",
      "max_value 319.90108674484503\n",
      "Score: 982.6301218901723\n",
      "max_value 319.90108674484503\n",
      "Score: 982.6301218901723\n",
      "max_value 319.90108674484503\n",
      "Score: 982.6301218901723\n",
      "max_value 255.92086939587603\n",
      "Score: 982.6301218901723\n",
      "max_value 319.90108674484503\n",
      "Score: 982.6301218901723\n",
      "max_value 319.90108674484503\n",
      "Score: 982.6301218901723\n",
      "max_value 399.87635843105625\n",
      "Score: 982.6301218901723\n",
      "max_value 499.8454480388203\n",
      "Score: 982.6301218901723\n",
      "max_value 255.92086939587603\n",
      "Score: 982.6301218901723\n",
      "max_value 255.92086939587603\n",
      "Score: 982.6301218901723\n",
      "max_value 255.92086939587603\n",
      "Score: 982.6301218901723\n",
      "max_value 319.90108674484503\n",
      "Score: 982.6301218901723\n",
      "max_value 399.87635843105625\n",
      "Score: 982.6301218901723\n",
      "max_value 319.90108674484503\n",
      "Score: 982.6301218901723\n",
      "max_value 255.92086939587603\n",
      "Score: 982.6301218901723\n",
      "max_value 399.87635843105625\n",
      "Score: 982.6301218901723\n",
      "max_value 255.92086939587603\n",
      "Score: 982.652940813061\n",
      "max_value 255.92086939587603\n",
      "Score: 982.652940813061\n",
      "max_value 255.92086939587603\n",
      "Score: 982.652940813061\n",
      "max_value 255.92086939587603\n",
      "Score: 982.652940813061\n",
      "max_value 319.90108674484503\n",
      "Score: 982.652940813061\n",
      "max_value 499.8454480388203\n",
      "Score: 982.6606708004895\n",
      "max_value 399.87635843105625\n",
      "Score: 982.6606708004895\n",
      "max_value 255.92086939587603\n",
      "Score: 982.6606708004895\n",
      "max_value 399.87635843105625\n",
      "Score: 982.6606708004895\n",
      "max_value 499.87635843105625\n",
      "Score: 982.6060905286172\n",
      "max_value 319.90108674484503\n",
      "Score: 982.6060905286172\n",
      "max_value 255.92086939587603\n",
      "Score: 982.6060905286172\n",
      "max_value 255.92086939587603\n",
      "Score: 982.6060905286172\n",
      "max_value 399.90108674484503\n",
      "Score: 982.6110374146565\n",
      "max_value 499.87635843105625\n",
      "Score: 982.6172210222055\n",
      "max_value 255.92086939587603\n",
      "Score: 982.6400385340617\n",
      "max_value 255.92086939587603\n",
      "Score: 982.6400385340617\n",
      "max_value 399.90108674484503\n",
      "Score: 982.6400385340617\n",
      "max_value 499.90108674484503\n",
      "Score: 982.5963774970802\n",
      "max_value 319.90108674484503\n",
      "Score: 982.5963774970802\n",
      "max_value 319.920869395876\n",
      "Score: 982.6003348101477\n",
      "max_value 319.920869395876\n",
      "Score: 982.6003348101477\n",
      "max_value 255.92086939587603\n",
      "Score: 982.6003348101477\n",
      "max_value 499.90108674484503\n",
      "Score: 982.6052814514823\n",
      "max_value 255.92086939587603\n",
      "Score: 982.6052814514823\n",
      "max_value 255.92086939587603\n",
      "Score: 982.6052814514823\n",
      "max_value 499.920869395876\n",
      "Score: 982.5703553794779\n",
      "max_value 204.73669551670082\n",
      "Score: 982.5886077636984\n",
      "max_value 204.73669551670082\n",
      "Score: 982.5886077636984\n",
      "max_value 255.92086939587603\n",
      "Score: 982.5886077636984\n",
      "max_value 255.92086939587603\n",
      "Score: 982.5886077636984\n",
      "max_value 499.93669551670087\n",
      "Score: 982.5606683184237\n",
      "max_value 399.920869395876\n",
      "Score: 982.5695716386278\n",
      "max_value 319.90108674484503\n",
      "Score: 982.5695716386278\n",
      "max_value 319.90108674484503\n",
      "Score: 982.5695716386278\n",
      "max_value 255.92086939587603\n",
      "Score: 982.5695716386278\n",
      "max_value 399.920869395876\n",
      "Score: 982.5695716386278\n",
      "max_value 255.92086939587603\n",
      "Score: 982.5695716386278\n",
      "max_value 255.92086939587603\n",
      "Score: 982.5695716386278\n",
      "max_value 499.9493564133607\n",
      "Score: 982.5543436063115\n",
      "max_value 319.920869395876\n",
      "Score: 982.5543436063115\n",
      "max_value 399.95948513068856\n",
      "Score: 982.562067535609\n",
      "max_value 255.92086939587603\n",
      "Score: 982.562067535609\n",
      "max_value 255.92086939587603\n",
      "Score: 982.562067535609\n",
      "max_value 255.92086939587603\n",
      "Score: 982.562067535609\n",
      "max_value 204.73669551670082\n",
      "Score: 982.562067535609\n",
      "max_value 255.92086939587603\n",
      "Score: 982.562067535609\n",
      "max_value 255.92086939587603\n",
      "Score: 982.562067535609\n",
      "max_value 255.92086939587603\n",
      "Score: 982.562067535609\n",
      "max_value 319.90108674484503\n",
      "Score: 982.562067535609\n",
      "max_value 319.90108674484503\n",
      "Score: 982.562067535609\n",
      "max_value 499.9493564133607\n",
      "Score: 982.5645999714442\n",
      "max_value 319.90108674484503\n",
      "Score: 982.5645999714442\n",
      "max_value 499.95948513068856\n",
      "Score: 982.5467200279237\n",
      "max_value 319.90108674484503\n",
      "Score: 982.5467200279237\n",
      "max_value 255.92086939587603\n",
      "Score: 982.5467200279237\n",
      "max_value 255.92086939587603\n",
      "Score: 982.5467200279237\n",
      "max_value 499.9675881045509\n",
      "Score: 982.534442469502\n",
      "max_value 399.97407048364073\n",
      "Score: 982.5373597292003\n",
      "max_value 255.92086939587603\n",
      "Score: 982.5373597292003\n",
      "max_value 204.73669551670082\n",
      "Score: 982.5373597292003\n",
      "max_value 319.90108674484503\n",
      "Score: 982.5373597292003\n",
      "max_value 255.92086939587603\n",
      "Score: 982.5373597292003\n",
      "max_value 499.9675881045509\n",
      "Score: 982.5389804290328\n",
      "max_value 255.92086939587603\n",
      "Score: 982.5389804290328\n",
      "max_value 255.92086939587603\n",
      "Score: 982.5389804290328\n",
      "max_value 255.92086939587603\n",
      "Score: 982.5389804290328\n",
      "max_value 319.90108674484503\n",
      "Score: 982.5389804290328\n",
      "max_value 399.97407048364073\n",
      "Score: 982.5389804290328\n",
      "max_value 255.92086939587603\n",
      "Score: 982.5389804290328\n",
      "max_value 255.92086939587603\n",
      "Score: 982.5389804290328\n",
      "max_value 399.97407048364073\n",
      "Score: 982.5389804290328\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max_value 204.73669551670082\n",
      "Score: 982.557231107687\n",
      "max_value 255.92086939587603\n",
      "Score: 982.557231107687\n",
      "max_value 255.92086939587603\n",
      "Score: 982.557231107687\n",
      "max_value 255.92086939587603\n",
      "Score: 982.557231107687\n",
      "max_value 399.97407048364073\n",
      "Score: 982.571828801724\n",
      "max_value 399.97407048364073\n",
      "Score: 982.571828801724\n",
      "max_value 255.92086939587603\n",
      "Score: 982.571828801724\n",
      "max_value 204.73669551670082\n",
      "Score: 982.571828801724\n",
      "max_value 399.97407048364073\n",
      "Score: 982.571828801724\n",
      "max_value 255.92086939587603\n",
      "Score: 982.571828801724\n",
      "max_value 399.97407048364073\n",
      "Score: 982.571828801724\n",
      "max_value 255.92086939587603\n",
      "Score: 982.571828801724\n",
      "max_value 319.9792563869126\n",
      "Score: 982.5835069569537\n",
      "max_value 399.97407048364073\n",
      "Score: 982.5835069569537\n",
      "max_value 319.90108674484503\n",
      "Score: 982.5835069569537\n",
      "max_value 319.90108674484503\n",
      "Score: 982.5835069569537\n",
      "max_value 319.9792563869126\n",
      "Score: 982.5835069569537\n",
      "max_value 319.90108674484503\n",
      "Score: 982.5835069569537\n",
      "max_value 319.90108674484503\n",
      "Score: 982.5835069569537\n",
      "max_value 255.92086939587603\n",
      "Score: 982.5835069569537\n",
      "max_value 255.92086939587603\n",
      "Score: 982.5835069569537\n",
      "max_value 255.92086939587603\n",
      "Score: 982.5835069569537\n",
      "max_value 499.97407048364073\n",
      "Score: 982.5720638817857\n",
      "max_value 255.92086939587603\n",
      "Score: 982.5720638817857\n",
      "max_value 255.92086939587603\n",
      "Score: 982.5720638817857\n",
      "max_value 399.9792563869126\n",
      "Score: 982.5731011162301\n",
      "max_value 399.9792563869126\n",
      "Score: 982.5731011162301\n",
      "max_value 499.97407048364073\n",
      "Score: 982.5743976592855\n",
      "max_value 204.73669551670082\n",
      "Score: 982.5743976592855\n",
      "max_value 399.9792563869126\n",
      "Score: 982.5743976592855\n",
      "max_value 255.92086939587603\n",
      "Score: 982.5743976592855\n",
      "max_value 255.92086939587603\n",
      "Score: 982.5743976592855\n",
      "max_value 319.9834051095301\n",
      "Score: 982.5752274468409\n",
      "max_value 319.90108674484503\n",
      "Score: 982.5752274468409\n",
      "max_value 399.9792563869126\n",
      "Score: 982.5752274468409\n",
      "max_value 399.9792563869126\n",
      "Score: 982.5762646812852\n",
      "max_value 499.9792563869126\n",
      "Score: 982.5671103912218\n",
      "max_value 399.9792563869126\n",
      "Score: 982.5671103912218\n",
      "max_value 499.9834051095301\n",
      "Score: 982.5597870958986\n",
      "max_value 319.90108674484503\n",
      "Score: 982.5597870958986\n",
      "max_value 204.73669551670082\n",
      "Score: 982.5597870958986\n",
      "max_value 319.90108674484503\n",
      "Score: 982.5597870958986\n",
      "max_value 255.92086939587603\n",
      "Score: 982.5597870958986\n",
      "max_value 319.90108674484503\n",
      "Score: 982.5597870958986\n",
      "max_value 255.92086939587603\n",
      "Score: 982.5597870958986\n",
      "max_value 499.9867240876241\n",
      "Score: 982.5539285471434\n",
      "max_value 399.9792563869126\n",
      "Score: 982.5539285471434\n",
      "max_value 204.73669551670082\n",
      "Score: 982.5539285471434\n",
      "max_value 255.92086939587603\n",
      "Score: 982.5539285471434\n",
      "max_value 499.98937927009933\n",
      "Score: 982.5492417641403\n",
      "max_value 255.92086939587603\n",
      "Score: 982.5492417641403\n",
      "max_value 319.90108674484503\n",
      "Score: 982.5492417641403\n",
      "max_value 319.90108674484503\n",
      "Score: 982.5492417641403\n",
      "max_value 319.90108674484503\n",
      "Score: 982.5492417641403\n",
      "max_value 399.9792563869126\n",
      "Score: 982.5492417641403\n",
      "max_value 255.92086939587603\n",
      "Score: 982.5492417641403\n",
      "max_value 255.92086939587603\n",
      "Score: 982.5492417641403\n",
      "max_value 399.9792563869126\n",
      "Score: 982.5492417641403\n",
      "max_value 204.73669551670082\n",
      "Score: 982.5492417641403\n",
      "max_value 399.9792563869126\n",
      "Score: 982.5698217924614\n",
      "max_value 255.92086939587603\n",
      "Score: 982.5698217924614\n",
      "max_value 499.99150341607947\n",
      "Score: 982.5660723144675\n",
      "max_value 255.92086939587603\n",
      "Score: 982.5660723144675\n",
      "max_value 204.73669551670082\n",
      "Score: 982.5660723144675\n",
      "max_value 255.92086939587603\n",
      "Score: 982.5660723144675\n",
      "max_value 255.92086939587603\n",
      "Score: 982.5660723144675\n",
      "max_value 204.73669551670082\n",
      "Score: 982.5660723144675\n",
      "max_value 499.9932027328636\n",
      "Score: 982.5665593888973\n",
      "max_value 204.73669551670082\n",
      "Score: 982.5665593888973\n",
      "max_value 319.9834051095301\n",
      "Score: 982.5830232856533\n",
      "max_value 399.9945621862909\n",
      "Score: 982.5860844871445\n",
      "max_value 319.9834051095301\n",
      "Score: 982.5860844871445\n",
      "max_value 255.92086939587603\n",
      "Score: 982.5860844871445\n",
      "max_value 319.9834051095301\n",
      "Score: 982.6025483839005\n",
      "max_value 399.9945621862909\n",
      "Score: 982.6056095853919\n",
      "max_value 319.99564974903274\n",
      "Score: 982.6080585465849\n",
      "max_value 499.9932027328636\n",
      "Score: 982.608398414562\n",
      "max_value 255.9867240876241\n",
      "Score: 982.6215695319668\n",
      "max_value 204.73669551670082\n",
      "Score: 982.6215695319668\n",
      "max_value 319.99564974903274\n",
      "Score: 982.6240184931598\n",
      "max_value 499.9945621862909\n",
      "Score: 982.6216186945667\n",
      "max_value 255.9965197992262\n",
      "Score: 982.6235778581943\n",
      "max_value 255.9965197992262\n",
      "Score: 982.6235778581943\n",
      "max_value 255.9965197992262\n",
      "Score: 982.6387081034152\n",
      "max_value 399.99564974903274\n",
      "Score: 982.6389256183292\n",
      "max_value 399.99564974903274\n",
      "Score: 982.6389256183292\n",
      "max_value 204.79721583938098\n",
      "Score: 982.6510298145059\n",
      "max_value 319.99564974903274\n",
      "Score: 982.6699426210321\n",
      "max_value 255.9965197992262\n",
      "Score: 982.6699426210321\n",
      "max_value 255.9965197992262\n",
      "Score: 982.6699426210321\n",
      "max_value 255.9965197992262\n",
      "Score: 982.6699426210321\n",
      "max_value 399.99564974903274\n",
      "Score: 982.6732213291141\n",
      "max_value 399.99564974903274\n",
      "Score: 982.673438844028\n",
      "max_value 399.99564974903274\n",
      "Score: 982.673438844028\n",
      "max_value 255.9965197992262\n",
      "Score: 982.673438844028\n",
      "max_value 204.79721583938098\n",
      "Score: 982.6855430402048\n",
      "max_value 319.99651979922623\n",
      "Score: 982.685717052136\n",
      "max_value 255.997215839381\n",
      "Score: 982.685856261681\n",
      "max_value 255.997215839381\n",
      "Score: 982.7011257164469\n",
      "max_value 399.99564974903274\n",
      "Score: 982.7011257164469\n",
      "max_value 319.99651979922623\n",
      "Score: 982.701299728378\n",
      "max_value 319.99651979922623\n",
      "Score: 982.701299728378\n",
      "max_value 255.997215839381\n",
      "Score: 982.701299728378\n",
      "max_value 399.99564974903274\n",
      "Score: 982.701299728378\n",
      "max_value 399.99564974903274\n",
      "Score: 982.701299728378\n",
      "max_value 399.99564974903274\n",
      "Score: 982.701299728378\n",
      "max_value 399.99564974903274\n",
      "Score: 982.701299728378\n",
      "max_value 399.99564974903274\n",
      "Score: 982.701299728378\n",
      "max_value 319.99651979922623\n",
      "Score: 982.7014737403092\n",
      "max_value 255.997215839381\n",
      "Score: 982.7014737403092\n",
      "max_value 399.99564974903274\n",
      "Score: 982.7014737403092\n",
      "max_value 399.99564974903274\n",
      "Score: 982.7014737403092\n",
      "max_value 319.99651979922623\n",
      "Score: 982.7014737403092\n",
      "max_value 319.99651979922623\n",
      "Score: 982.7014737403092\n",
      "max_value 255.997215839381\n",
      "Score: 982.7014737403092\n",
      "max_value 255.997215839381\n",
      "Score: 982.7016129498542\n",
      "max_value 399.99564974903274\n",
      "Score: 982.7016129498542\n",
      "max_value 255.997215839381\n",
      "Score: 982.71688240462\n",
      "max_value 399.99564974903274\n",
      "Score: 982.71688240462\n",
      "max_value 399.99564974903274\n",
      "Score: 982.71688240462\n",
      "max_value 499.9945621862909\n",
      "Score: 982.7171542982626\n",
      "max_value 255.997215839381\n",
      "Score: 982.7171542982626\n",
      "max_value 319.99651979922623\n",
      "Score: 982.7171542982626\n",
      "max_value 255.997215839381\n",
      "Score: 982.7171542982626\n",
      "max_value 399.99564974903274\n",
      "Score: 982.7171542982626\n",
      "max_value 319.99651979922623\n",
      "Score: 982.7171542982626\n",
      "max_value 319.99651979922623\n",
      "Score: 982.7171542982626\n",
      "max_value 499.99564974903274\n",
      "Score: 982.7152342609801\n",
      "max_value 255.997215839381\n",
      "Score: 982.7152342609801\n",
      "max_value 399.99564974903274\n",
      "Score: 982.7152342609801\n",
      "max_value 255.997215839381\n",
      "Score: 982.7152342609801\n",
      "max_value 319.99651979922623\n",
      "Score: 982.7152342609801\n",
      "max_value 204.79777267150482\n",
      "Score: 982.7153456283738\n",
      "max_value 319.99651979922623\n",
      "Score: 982.7179685891342\n",
      "max_value 204.79777267150482\n",
      "Score: 982.7180799565278\n",
      "max_value 399.99564974903274\n",
      "Score: 982.7180799565278\n",
      "max_value 255.997215839381\n",
      "Score: 982.7180799565278\n",
      "max_value 319.99651979922623\n",
      "Score: 982.7180799565278\n",
      "max_value 255.997215839381\n",
      "Score: 982.7180799565278\n",
      "max_value 204.79777267150482\n",
      "Score: 982.7180799565278\n",
      "max_value 255.997215839381\n",
      "Score: 982.7180799565278\n",
      "max_value 204.79777267150482\n",
      "Score: 982.7180799565278\n",
      "max_value 255.997215839381\n",
      "Score: 982.7180799565278\n",
      "max_value 255.997215839381\n",
      "Score: 982.7180799565278\n",
      "max_value 499.99651979922623\n",
      "Score: 982.7165439277638\n",
      "max_value 319.99651979922623\n",
      "Score: 982.7165439277638\n",
      "max_value 399.99564974903274\n",
      "Score: 982.7165439277638\n",
      "max_value 399.99564974903274\n",
      "Score: 982.7165439277638\n",
      "max_value 204.79777267150482\n",
      "Score: 982.7165439277638\n",
      "max_value 255.997215839381\n",
      "Score: 982.7165439277638\n",
      "max_value 399.99564974903274\n",
      "Score: 982.7165439277638\n",
      "max_value 255.997215839381\n",
      "Score: 982.7165439277638\n",
      "max_value 255.997215839381\n",
      "Score: 982.7165439277638\n",
      "max_value 399.99564974903274\n",
      "Score: 982.7165439277638\n",
      "max_value 255.997215839381\n",
      "Score: 982.7165439277638\n",
      "max_value 204.79777267150482\n",
      "Score: 982.7165439277638\n",
      "max_value 319.99651979922623\n",
      "Score: 982.7165439277638\n",
      "max_value 255.997215839381\n",
      "Score: 982.7165439277638\n",
      "max_value 255.997215839381\n",
      "Score: 982.7165439277638\n",
      "max_value 399.99564974903274\n",
      "Score: 982.7165439277638\n",
      "max_value 319.99651979922623\n",
      "Score: 982.7165439277638\n",
      "max_value 499.997215839381\n",
      "Score: 982.715706633369\n",
      "max_value 399.99777267150483\n",
      "Score: 982.7161312202277\n",
      "max_value 255.997215839381\n",
      "Score: 982.7161312202277\n",
      "max_value 399.99777267150483\n",
      "Score: 982.7165558070864\n",
      "max_value 255.997215839381\n",
      "Score: 982.7165558070864\n",
      "max_value 319.99651979922623\n",
      "Score: 982.7165558070864\n",
      "max_value 499.997215839381\n",
      "Score: 982.7165558070864\n",
      "max_value 255.997215839381\n",
      "Score: 982.7165558070864\n",
      "max_value 399.99777267150483\n",
      "Score: 982.7165558070864\n",
      "max_value 399.99777267150483\n",
      "Score: 982.7165558070864\n",
      "max_value 255.997215839381\n",
      "Score: 982.7165558070864\n",
      "max_value 319.99651979922623\n",
      "Score: 982.7165558070864\n",
      "max_value 319.99651979922623\n",
      "Score: 982.7165558070864\n",
      "max_value 399.99777267150483\n",
      "Score: 982.7165558070864\n",
      "max_value 204.79777267150482\n",
      "Score: 982.7165558070864\n",
      "max_value 499.997215839381\n",
      "Score: 982.7165558070864\n",
      "max_value 399.99777267150483\n",
      "Score: 982.7165558070864\n",
      "max_value 499.997215839381\n",
      "Score: 982.7166950158925\n",
      "max_value 499.99777267150483\n",
      "Score: 982.7157119614892\n",
      "max_value 255.997215839381\n",
      "Score: 982.7157119614892\n",
      "max_value 399.9982181372039\n",
      "Score: 982.7158010550258\n",
      "max_value 255.997215839381\n",
      "Score: 982.7158010550258\n",
      "max_value 399.9982181372039\n",
      "Score: 982.7158901485625\n",
      "max_value 499.99777267150483\n",
      "Score: 982.7160015154833\n",
      "max_value 319.99651979922623\n",
      "Score: 982.7160015154833\n",
      "max_value 255.997215839381\n",
      "Score: 982.7160015154833\n",
      "max_value 255.997215839381\n",
      "Score: 982.7160015154833\n",
      "max_value 255.997215839381\n",
      "Score: 982.7160015154833\n",
      "max_value 319.99651979922623\n",
      "Score: 982.7160015154833\n",
      "max_value 255.997215839381\n",
      "Score: 982.7160015154833\n",
      "max_value 319.9985745097631\n",
      "Score: 982.7164124594213\n",
      "max_value 255.997215839381\n",
      "Score: 982.7164124594213\n",
      "max_value 319.99651979922623\n",
      "Score: 982.7164124594213\n",
      "max_value 319.99651979922623\n",
      "Score: 982.7164124594213\n",
      "max_value 319.99651979922623\n",
      "Score: 982.7164124594213\n",
      "max_value 399.9982181372039\n",
      "Score: 982.7164124594213\n",
      "max_value 255.997215839381\n",
      "Score: 982.7164124594213\n",
      "max_value 399.9982181372039\n",
      "Score: 982.7164124594213\n",
      "max_value 319.99651979922623\n",
      "Score: 982.7164124594213\n",
      "max_value 319.99651979922623\n",
      "Score: 982.7164124594213\n",
      "max_value 319.99651979922623\n",
      "Score: 982.7164124594213\n",
      "max_value 399.9982181372039\n",
      "Score: 982.7164124594213\n",
      "max_value 319.99651979922623\n",
      "Score: 982.7164124594213\n",
      "max_value 255.997215839381\n",
      "Score: 982.7164124594213\n",
      "max_value 255.997215839381\n",
      "Score: 982.7164124594213\n",
      "max_value 255.997215839381\n",
      "Score: 982.7164124594213\n",
      "max_value 399.9982181372039\n",
      "Score: 982.7164124594213\n",
      "max_value 204.79777267150482\n",
      "Score: 982.7164124594213\n",
      "max_value 255.997215839381\n",
      "Score: 982.7164124594213\n",
      "max_value 399.9982181372039\n",
      "Score: 982.7164124594213\n",
      "max_value 319.99651979922623\n",
      "Score: 982.7164124594213\n",
      "max_value 255.997215839381\n",
      "Score: 982.7164124594213\n",
      "max_value 499.9982181372039\n",
      "Score: 982.7156260168513\n",
      "Trained Q matrix:\n",
      "[[  0.          63.99953204   0.           0.           0.\n",
      "    0.           0.           0.        ]\n",
      " [ 51.19962563   0.          51.19962563   0.           0.\n",
      "   79.99941505   0.           0.        ]\n",
      " [  0.          63.99953204   0.          40.9597005   40.9597005\n",
      "    0.           0.           0.        ]\n",
      " [  0.           0.          51.19962563   0.           0.\n",
      "    0.           0.           0.        ]\n",
      " [  0.           0.          51.19962563   0.           0.\n",
      "    0.           0.           0.        ]\n",
      " [  0.          63.99953204   0.           0.           0.\n",
      "    0.          63.99994298  99.99991091]\n",
      " [  0.           0.           0.           0.           0.\n",
      "   79.99992873   0.           0.        ]\n",
      " [  0.           0.           0.           0.           0.\n",
      "   79.99992873   0.         100.        ]]\n"
     ]
    }
   ],
   "source": [
    "scores = []\n",
    "for i in range(1000):\n",
    "    estado_actual = np.random.randint(0, int(Q.shape[0]))\n",
    "    act_posible = acciones_posibles(estado_actual)\n",
    "    action = proxima_accion(act_posible)\n",
    "    score = update(estado_actual,action,gamma)\n",
    "    scores.append(score)\n",
    "    print ('Score:', str(score))\n",
    "\n",
    "print(\"Trained Q matrix:\")\n",
    "print(Q/np.max(Q)*100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aplicamos la función de test que nos dará la ruta óptima."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most efficient path:\n",
      "[0, 1, 5, 7]\n"
     ]
    }
   ],
   "source": [
    "estado_actual = 0\n",
    "steps = [estado_actual]\n",
    "\n",
    "while estado_actual != 7:\n",
    "\n",
    "    next_step_index = np.where(Q[estado_actual,]== np.max(Q[estado_actual,]))[1]\n",
    "\n",
    "    if next_step_index.shape[0] > 1:\n",
    "        next_step_index =int(np.random.choice(next_step_index, size = 1))\n",
    "    else:\n",
    "        next_step_index = int(next_step_index)\n",
    "\n",
    "    steps.append(next_step_index)\n",
    "    estado_actual = next_step_index\n",
    "\n",
    "print(\"Most efficient path:\")\n",
    "print(steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(scores)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como podemos ver, aproximadamente en el intento 300 Juan ha aprendido exactamente cual es su ruta al trabajo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2. Método de Monte Carlo\n",
    "\n",
    "<a id=\"monte\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Los métodos de Monte Carlo sólo requieren una muestra de *experiencia*, es decir, secuencias de estados, acciones y recompensas de la interacción real o simulada con el entorno. Aprender de experiencia real es sorprendente porque aunque no requiere ningún tipo de conocimiento de la dinámica del ambiente, puede lograr un comportamiento óptimo. El aprendizaje de experiencia simulada también es poderoso. Aunque se requiere un modelo, el modelo sólo necesita generar transiciones de la muestra, no las distribuciones de probabilidad completas de todas las posibles transiciones, como por ejemplo, se requieren para la programación dinámica (PD). En muchos casos, es fácil generar experiencia muestreada según las distribuciones de probabilidad deseadas,\n",
    "pero no es posible obtener las distribuciones de forma explícita."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "De nuevo, realizamos un ejemplo para la mejor comprensión:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Ejemplo aplicado a Python"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Supongamos que Juan lleva ya varios meses viviendo en la ciudad y, para despejarse, tiene ahora por costumbre darse un paseo a la vuelta del trabajo. Puesto que está sometido a mucho estrés, no puede evitar pensar en los proyectos que tiene pendientes, y no es la primera vez que acaba alejándose tanto de su casa que tiene que volver en autobús. Juan considera que se encuentra a una distancia alejada cada vez que, una vez finalizado su paseo, esté a más de 4 manzanas de su punto de partida. \n",
    "\n",
    "Nos interesa estudiar cuál es la mayor distancia que, de media, podrá recorrer sin tener que coger el autobús. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para esta simulación de Monte Carlo debemos tener en cuenta varios puntos:\n",
    "\n",
    "1. Consideraremos la máxima distancia permitida aquella que, en más de la mitad de las veces, le permita volver andando a casa.\n",
    "\n",
    "\n",
    "2. Cabe recordar que Juan se encuentra en el centro de la ciudad. Por lo tanto, el mapa tendrá forma de cuadrícula, representando cada uno de los cuadrados una manzana distinta. \n",
    "\n",
    "\n",
    "3. Cada vez que Juan llegue a una intersección, tendrá que elegir entre 4 direcciones posibles: Norte, Sur, Este u Oeste. Es posible que vuelva hacia atrás.\n",
    "\n",
    "\n",
    "4. En la simulación mediremos la distancia andada en \"manzanas recorridas\", que recoge el número de veces que Juan ha andado la distancia de un lado de una manzana. Es decir, si Juan diera la vuelta entera a una manzana, contaríamos que ha andado la distancia de 4 manzanas.\n",
    "\n",
    "\n",
    "5. Juan cojerá el autobús siempre que, una vez finalizado su trayecto, se encuentre a una distancia superior a 4 manzanas. Puede darse el caso de que haya podido andar, por ejemplo, una distancia de 30 bloques, pero que al acabar el paseo se encuentre a tan solo 2 de su punto de partida. En ese caso, no haría uso de transporte público para volver a casa."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cargamos el paquete random."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creamos la función \"paseo_aleatorio\", para medir la distancia andada. Utilizamos x e y, los cuales añadirán y sustraerán valores en función de la dirección cardinal que Juan tome en cada intersección. Por ejemplo, si toma la dirección Norte, el valor de la \"x\" permanecerá igual, y a la \"y\" se le sumará un 1. Usamos también x += dx, que es lo mismo que x = x + dx, para actualizar el valor de cada dirección tomada."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "def paseo_aleatorio(n):\n",
    "    \"\"\"Devolver coordenadas tras 'n' manzanas recorridas\"\"\"\n",
    "    x, y = 0, 0\n",
    "    for i in range(n):\n",
    "        (dx, dy) = random.choice ([(0, 1), (0, -1), (1, 0), (-1, 0)])\n",
    "        x += dx \n",
    "        y += dy\n",
    "    return(x, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Seleccionamos un número de 1000 paseos con los que realizar la simulación."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "numero_de_paseos = 1000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A continuación, estudiamos las probabilidad de que Juan tenga que coger el autobús al recorrer una distancia de 1 a 50 bloques. creamos un bucle que compute las veces que la distancia a la que se encuentre Juan al finalizar su paseo sea igual o inferior a 4 bloques, sumando un valor 1. Al final, se contabilizarán las veces que vuelve andando a casa para cada distancia recorrida, dividido en el total de veces que recorre esa distancia."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Manzanas andadas = 1 / sin usar transporte público = 100.0\n",
      "Manzanas andadas = 2 / sin usar transporte público = 100.0\n",
      "Manzanas andadas = 3 / sin usar transporte público = 100.0\n",
      "Manzanas andadas = 4 / sin usar transporte público = 100.0\n",
      "Manzanas andadas = 5 / sin usar transporte público = 88.9\n",
      "Manzanas andadas = 6 / sin usar transporte público = 95.3\n",
      "Manzanas andadas = 7 / sin usar transporte público = 76.6\n",
      "Manzanas andadas = 8 / sin usar transporte público = 86.3\n",
      "Manzanas andadas = 9 / sin usar transporte público = 68.4\n",
      "Manzanas andadas = 10 / sin usar transporte público = 79.4\n",
      "Manzanas andadas = 11 / sin usar transporte público = 58.3\n",
      "Manzanas andadas = 12 / sin usar transporte público = 73.3\n",
      "Manzanas andadas = 13 / sin usar transporte público = 55.00000000000001\n",
      "Manzanas andadas = 14 / sin usar transporte público = 66.4\n",
      "Manzanas andadas = 15 / sin usar transporte público = 47.199999999999996\n",
      "Manzanas andadas = 16 / sin usar transporte público = 62.8\n",
      "Manzanas andadas = 17 / sin usar transporte público = 45.2\n",
      "Manzanas andadas = 18 / sin usar transporte público = 54.800000000000004\n",
      "Manzanas andadas = 19 / sin usar transporte público = 44.2\n",
      "Manzanas andadas = 20 / sin usar transporte público = 53.6\n",
      "Manzanas andadas = 21 / sin usar transporte público = 36.4\n",
      "Manzanas andadas = 22 / sin usar transporte público = 51.5\n",
      "Manzanas andadas = 23 / sin usar transporte público = 35.0\n",
      "Manzanas andadas = 24 / sin usar transporte público = 47.599999999999994\n",
      "Manzanas andadas = 25 / sin usar transporte público = 34.9\n",
      "Manzanas andadas = 26 / sin usar transporte público = 43.6\n",
      "Manzanas andadas = 27 / sin usar transporte público = 28.9\n",
      "Manzanas andadas = 28 / sin usar transporte público = 43.3\n",
      "Manzanas andadas = 29 / sin usar transporte público = 28.7\n",
      "Manzanas andadas = 30 / sin usar transporte público = 40.699999999999996\n",
      "Manzanas andadas = 31 / sin usar transporte público = 28.000000000000004\n",
      "Manzanas andadas = 32 / sin usar transporte público = 40.6\n",
      "Manzanas andadas = 33 / sin usar transporte público = 24.2\n",
      "Manzanas andadas = 34 / sin usar transporte público = 36.3\n",
      "Manzanas andadas = 35 / sin usar transporte público = 24.0\n",
      "Manzanas andadas = 36 / sin usar transporte público = 34.8\n",
      "Manzanas andadas = 37 / sin usar transporte público = 23.200000000000003\n",
      "Manzanas andadas = 38 / sin usar transporte público = 35.5\n",
      "Manzanas andadas = 39 / sin usar transporte público = 23.400000000000002\n",
      "Manzanas andadas = 40 / sin usar transporte público = 33.0\n",
      "Manzanas andadas = 41 / sin usar transporte público = 22.8\n",
      "Manzanas andadas = 42 / sin usar transporte público = 30.9\n",
      "Manzanas andadas = 43 / sin usar transporte público = 20.3\n",
      "Manzanas andadas = 44 / sin usar transporte público = 31.8\n",
      "Manzanas andadas = 45 / sin usar transporte público = 19.900000000000002\n",
      "Manzanas andadas = 46 / sin usar transporte público = 30.5\n",
      "Manzanas andadas = 47 / sin usar transporte público = 19.8\n",
      "Manzanas andadas = 48 / sin usar transporte público = 29.5\n",
      "Manzanas andadas = 49 / sin usar transporte público = 17.4\n"
     ]
    }
   ],
   "source": [
    "for distancia_paseo in range(1, 50):\n",
    "    vuelta_andando = 0\n",
    "    for i in range(numero_de_paseos):\n",
    "        (x, y) = paseo_aleatorio(distancia_paseo)\n",
    "        distancia = abs(x) + abs(y)\n",
    "        if distancia <= 4:\n",
    "            vuelta_andando += 1\n",
    "    tasa_vueltas_andando = float(vuelta_andando)/numero_de_paseos\n",
    "    print(\"Manzanas recorridas =\",\n",
    "         distancia_paseo,\n",
    "         \"/ sin usar transporte público =\",\n",
    "         100*tasa_vueltas_andando)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En este caso, la máxima distancia que podrá recorrer sin tener que volver en autobús es 22 manzanas."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Métodos de Solución Aproximada\n",
    "\n",
    "<a id=\"aprox\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Los métodos de solución Tabular pueden ser limitados, porque cuando estamos tratando con espacios muy grandes, no es posible encontrar una política óptima o la función-valor óptima. Nuestro objetivo, en cambio, es encontrar una buena solución aproximada usando recursos computacionales limitados. A continuación se explicarán algunos de estos métodos de forma teórica. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.1 Predicción \"on-policy\" mediante aproximación\n",
    "\n",
    "<a id=\"onpolicy\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Este método va a considerar la estimación la función que devuelve el valor del estado con data \"on-policy\", esto es,\n",
    "aproximar $\\upsilon_{\\pi}$ a partir de la experiencia generada mediante una política conocida $\\pi$. La novedad es que la función de valor aproximada se representa no como una tabla sino como un forma funcional parametrizada con vector de peso $w\\in \\mathbb{R}^d$. Escribimos $\\hat{\\upsilon}(s,w) \\approx \\upsilon_{\\pi}(s)$, para el valor aproximado del estado $s$ dado el vector de pesos $w$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A continuación, debemos tener en cuenta la optimización de la función-valor, pero además, en este apartado, trataremos de encontrar un valor óptimo para la Predicción $(\\overline{VE})$, obtenida de la siguiente forma $$\\overline{VE}(w) = \\sum_{s\\in S}\\mu(s)[\\upsilon_{\\pi} - \\hat{\\upsilon}(s,w)]^2 $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Con estos componentes, pasaríamos obtener una solución óptima mediante técnicas basadas en descenso de gradiente estocástico. Como la notación matemática para la explicación de estos métodos, proporcionaremos un pseucódigo para estimar correctamente $\\hat{\\upsilon} \\approx \\upsilon_{\\pi}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Primero utilizaremos el algoritmo de gradiente de Monte Carlo. \n",
    "\n",
    "Tendríamos dos inputs:\n",
    "\n",
    "La política $\\pi$ que va a ser evaluada\n",
    "\n",
    "Una función diferenciable $\\hat{\\upsilon} : S \\times \\mathbb{R}^d \\rightarrow \\mathbb{R}$\n",
    "\n",
    "El parámetro del algoritmo: el tamaño del paso $\\alpha > 0$\n",
    "\n",
    "Inicializamos los pesos de la función valor arbitrariamente $w = 0$\n",
    "\n",
    "Hacemos un loop para cada episodio:\n",
    "\n",
    "   Generamos un episodio $S_{0}, A_{0}, R_{1}, S_{1}, A_{1},..., R_{T}, S_{T}$ utilizando $\\pi$\n",
    "    \n",
    "   Bucle para cada paso: $t = 0,1..., T-1:$\n",
    "        $w \\leftarrow w + \\alpha[G_{t} - \\hat{\\upsilon}(S_{t},w)]\\nabla\\hat{\\upsilon}(S_{t},w)$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En oposición a estos, existirían los métodos de bootstrapping. Aunque los métodos de semi gradiente (bootstrapping) no convergen con tanta fuerza como los métodos de gradientes, convergen de manera fiable en casos importantes como el caso lineal. Además, ofrecen importantes ventajas que los hacen a menudo, la opción preferida. Una razón para ello es que normalmente permiten una mayor rapidez de aprendizaje. Otra es que permiten aprender a ser continuo y en línea, sin esperar el final de un episodio. Esto les permite ser utilizados en problemas continuos y proporciona ventajas computacionales"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Caso de estudio: Las Damas de Samuel\n",
    "\n",
    "<a id=\"samuel\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Arthur Samuel fue uno de los primeros en hacer uso de métodos de búsqueda heurística y de lo que ahora llamaríamos aprendizaje temporal-difference. Sus jugadores de damas son casos de estudio instructivos además de ser de interés histórico.\n",
    "\n",
    "Samuel usó dos métodos principales de aprendizaje, el más simple de los cuales lo llamó aprendizaje de memoria. Consistía simplemente en guardar una descripción de cada posición del tablero encontrada durante la partida junto con su valor de respaldo determinado por el procedimiento minimax. El resultado fue que si una posición que ya se había encontrado fuese a ocurrir de nuevo como una posición terminal de un árbol de búsqueda, la profundidad de la búsqueda sería amplificada porque el valor de esta posición ya ha registrado los resultados de una o más búsquedas realizadas anteriormente. El problema inicial fue que el programa no fue diseñado a encontrar el camino más rápido a la victoria. \n",
    "\n",
    "El aprendizaje de memoria produjo una lenta pero continua mejora, siendo más efectivo para las fases de apertura y final de partida. Su programa acabó consiguió ser mejor que la media tras aprender practicando muchas partidas contra sí mismo, oponentes humanos, y de partidas históricas con aprendizaje supervisado."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El aprendizaje de memoria y otros aspectos del trabajo de Samuel se inclinan fuertemente hacia la idea esencial del aprendizaje temporal-difference, es decir, que el valor de un estado debe ser igual al valor de siguientes estados más probables. Samuel se acercó más a esta idea en su segundo método de aprendizaje, su procedimiento de \"aprendizaje por generalización\" para modificar los parámetros de la función-Valor. . Jugó a su programa muchos juegos contra otra versión de sí mismo y\n",
    "realizó una actualización después de cada movimiento. \n",
    "\n",
    "La idea de la actualización de Samuel está representada la figura más abajo mostrada. Cada círculo abierto representa una posición donde el programa mueve a continuación, una posición en movimiento, y cada círculo sólido representa una posición donde el oponente moverá a continuación. Cuando mueven los dos lados, el valor de cada posición en movimiento se actualiza, lo que resulta en una segunda posición en movimiento. La actualización se realiza hacia el valor minimax de una búsqueda lanzada desde la segunda posición en movimiento. Por lo tanto, el valor total del efecto la vuelta tras un movimiento completo sobre los eventos reales, y, a partir de ahí, trasladarse a eventos posibles\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"Caso_Samuel.PNG\" alt=\"Drawing\" style=\"width: 450px;\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sin embargo, al método de aprendizaje de Samuel le puede haber faltado una parte esencial de un buen de algoritmo temporal-difference . El aprendizaje de temporal-difference puede ser visto como una forma de hacer una función-valor coherente con ella misma, y esto lo podemos ver claramente en el método de Samuel. Pero también se necesita una forma de vincular la función-valor al verdadero valor de los estados. Esto se puede forzar aplicando recompensas y descontando o dando un valor fijo al estado terminal. Pero el método de Samuel no incluía recompensas ni un tratamiento especial de las posiciones terminales de las partidas. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Conclusiones\n",
    "\n",
    "<a id=\"conclu\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como hemos visto, el aprendizaje por refuerzo tiene aplicaciones muy importantes, ya que casi todas las incógnitas reales podrían ser escudriñadas a través del prisma de algún método que utilice este tipo de aprendizaje. Esto es así, porque las acciones están constantemente determinadas por los estímulos del entorno, y, por lo tanto podríamos situar el problema en un planteamiento de aprendizaje por refuerzo.\n",
    "\n",
    "A lo largo de esta exposición teórica de este tipo de aprendizaje, hemos visto por un lado, apoyados en ejemplos aclaratorios con código pyhton, dos de los métodos tabulares más conocidos. La simpleza de los métodos tabulares nos ha permitido plasmarlo mejor con ejemplo de código. Mientras que, por otro lado, hemos rascado en la superficie de otros métodos más complejos como son los de estimación aproximada, en un modesto acercamiento a los métodos \"on-policy\"\n",
    "\n",
    "Además de manera teórica, hemos visto algunos ejemplos en los que se ha utilizado métodos de aprendizaje por refuerzo, que nos han ayudado a comprender mejor la idiosincrasia de este tipo de aprendizaje.\n",
    "\n",
    "Aunque no era el objetivo de este trabajo, el camino por explorar, dentro de las cosas que se han hablado, y sobre todo, de las que se han omitido, es muy extenso. En cualquier caso, este documento puede servir de un buen punto de partida para la investigación más exhaustivo sobre un mundo que puede tener implicaciones prácticas muy interesantes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bibliografía\n",
    "\n",
    "<a id=\"biblio\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- https://towardsdatascience.com/reinforcement-learning-on-policy-function-approximation-2f47576f772d\n",
    "\n",
    "- https://github.com/ShangtongZhang/reinforcement-learning-an-introduction/blob/master/chapter09/square_wave.py\n",
    "\n",
    "- Busoniu, Lucian; Babuska, Robert; De Schutter, Bart; Ernst, Damien (2010). Reinforcement Learning and Dynamic Programming using Function Approximators. Taylor & Francis CRC Press. ISBN 978-1-4398-2108-4\n",
    "\n",
    "- Sutton, Richard S.; Barto, Andrew G. (2018). Reinforcement Learning: An Introduction (2ed.). MIT Press. ISBN 978-0-262-03924-6.\n",
    "\n",
    "- https://towardsdatascience.com/reinforcement-learning-in-a-few-lines-of-code-d6c8af1e0fd2"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
